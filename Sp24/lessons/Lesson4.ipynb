{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59bd53e",
   "metadata": {},
   "source": [
    "# Python Packages\n",
    "## Numpy, MatPlotLib, Cartopy\n",
    "\n",
    "In Python, a package is a bundle of pre-built functionality that adds to the functionality available in base Python. Base Python can do many things such as perform math and other operations. However, Python packages can significantly extend this functionality.\n",
    "\n",
    "You can think of a Python package as a toolbox filled with tools. The tools in the toolbox can be used to do things that you would have to otherwise hand code in base Python. These tasks are things that many people might want to do in Python, thus warranting the creation of a package. It doesn’t make sense for everyone to hard code everything.\n",
    "\n",
    "There are many different packages available for Python. Some of these are optimized for scientific tasks such as:\n",
    "* Statistics\n",
    "* Machine learning\n",
    "* Using geospatial data\n",
    "* Plotting & visualizing data\n",
    "* Accessing data programmatically\n",
    "\n",
    "Some important pacakges include: \n",
    "* **os:** handle files and directories.\n",
    "* **glob:** create lists of files and directories for batch processing.\n",
    "* **matplotlib:** plot data.\n",
    "* **numpy:** work with data in array formats (often related to imagery and raster format data).\n",
    "* **pandas:** work with tabular data in a DataFrame format.\n",
    "* **rasterio:** work with raster (image and arrays) data.\n",
    "* **geopandas:** work with vector format (shapefiles, geojson - points, lines and polygons) using a geodataframe format.\n",
    "* **cartopy:** plot and manipulate spatial data (raster and vector).\n",
    "\n",
    "### Python Packages Can Contain Modules\n",
    "Packages can contain many modules (i.e. units of code) that each provide different functions and can build on each other. For example, the matplotlib package provides functionality to plot data using modules, one of which is the commonly used module called pyplot.\n",
    "\n",
    "Every Python package should have a unique name. This allows you to import the package using the name with the `import` command.\n",
    "\n",
    "For example, the command below imports the matplotlib package.\n",
    "\n",
    "```python\n",
    "import matplotlib\n",
    "```\n",
    "\n",
    "Packages often have modules. For example, pyplot is a module within the matplotlib package that makes it easier to quickly set up plots.\n",
    "\n",
    "You can import a specific module like pyplot by first calling the package name and then the module name - using . to separate the names like this:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot\n",
    "```\n",
    "\n",
    "But, the better way to do this, is to use an *alias*: \n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "Aliases allows you to call functions from the imported package and/or module using the short name, rather than having to type out the full name of the packages and/or module each time that you want to call a function from it.\n",
    "\n",
    "Hot tip: You can get a list of the functions available using dir(np). A list of callable functions will appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993edf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dir(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec89320",
   "metadata": {},
   "source": [
    "## 1. Numpy\n",
    "\n",
    "Numpy arrays are a commonly used data structure in Python. You can think of arrays as a grid, or matrix.\n",
    "\n",
    "Like lists, numpy arrays are also composed of ordered values (called elements) and use indexing to organize and manipulate the elements in the numpy arrays. But, unlike lists, all elements in the array must be the same data type (i.e., all integeres, floats, text strings, etc). \n",
    "\n",
    "Numpy arrays can also have N dimensions (while lists, and tuples, etc only have one, and pandas dataframes have two.)\n",
    "\n",
    "And, unlike lists, which you can just use in native python, you need packaces to deal with arrays. Numpy is the most commonly-used package for arrays. And it is also the package which more sophisticated packages, like [xarray](https://xarray.dev/) and [rioxarray](https://corteva.github.io/rioxarray/stable/), are built off of.\n",
    "\n",
    "Arrays are defined like this `array()`. \n",
    "\n",
    "#### Key differences between lists and Numpy Arrays\n",
    "* Unlike a list, elements in a numpy array must be the same data type\n",
    "* Because of this, numpy arrays support aritmatic and other mathematical operations that run on each element of the array (e.g. element-by-element mutiplication). You cannot direcly apply a numeric calculation to a list. Generally need a for loop, etc.\n",
    "* Unlike a list, a numpy array isn't edited by adding/removing/replacing elements in the array. Instead, each time the array is manipulated, it's deleted and recreated each time.\n",
    "* Numpy arrays can store datae along N DIMENSIONS. This make numpy arrays super efficient if you're using a large dataset.\n",
    "\n",
    "### 1.1. Dimensionaity of Numpy Arrays\n",
    "Numpy arrays can be\n",
    "* 1. 1-D composed of values along one dimension - resembling a list\n",
    "* 2. 2-D composed of rows of individual arrays with one or more columns - like a pandas data frame but just the values w out headers.\n",
    "* 3. N-D composed of nested arrays with one or more dimensions. Prof Spera uses a lot of 3-d datasets. A global daily precipitation dataset will have rows/columns with data points of precip values and then a third, z / [time dimension](https://xarray.pydata.org/en/stable/_images/dataset-diagram.png). \n",
    "\n",
    "Brackets `[]` are used to assign the dimensions of a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd07b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a one-dimensional array of average precipitation for Jan, Feb, and March in Boulder, CO in 2023\n",
    "avg_monthly_pcp = np.array([0.7, 0.75, 1.85])\n",
    "print(avg_monthly_pcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a two d array of monthly precip Jan through Mar in 2002 and 2013\n",
    "pcp02_13 = np.array([\n",
    "    [1.07, 0.44, 1.50],\n",
    "    [0.27, 1.13, 1.72]\n",
    "])\n",
    "print(pcp02_13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfb2b6",
   "metadata": {},
   "source": [
    "### 1.2 Reading in a dataset\n",
    "One of the best ways to learn numpy is to deal w. real data. So let's have at it. First let's inspect the data, which is here in this directory: ../lab/PythonBootcamp/Sp24/resources/Lesson4.\n",
    "\n",
    "You can either look at the contents at in the terminal using some of our handy Linux commands. Or, in Jupyter Notebooks, navigate to /lab/PythonBootcamp/Sp24/resources/Lesson4 and double click on RVA_janfeb2024.csv to quickly look at the data. \n",
    "\n",
    "Regardless of how you inpect the data, you should see a description of the data, some column/variable headings, and then some data itself. Let's load this into numpy. (Running the next code block will kick out an error: why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/RVA_janfeb2024.csv\"\n",
    "\n",
    "tmpdata = np.genfromtxt(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2d211",
   "metadata": {},
   "source": [
    "That metadata/header at the top of the file that provides the basic information about the file contents, while helpful to us, is upsetting numpy. We only want the numpy elements to be the data themselves, because they all have to be the same data type, the array needs to be a rectangle or square. \n",
    "\n",
    "So, let's try and read it in again, and use `skip_header` to skip the top line, specify it's a comma delimited file using `delimiter`and we also we'er going to ingore the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdata = np.genfromtxt(file, skip_header=5, delimiter=',')\n",
    "print(tmpdata)\n",
    "\n",
    "type(tmpdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab4919",
   "metadata": {},
   "source": [
    "So, we just read our data into a NumPy ndarray, which is a type of NumPy n-dimensional structure used for storing data like a matrix. I our case we have a two dimensional data struture similar to a spreadsheet. Everything is together in a single large data structure at the moment, but we’ll see later in the lesson how to divide up our data and make interacting with it easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559a12e",
   "metadata": {},
   "source": [
    "### 1.3 Exploring a dataset\n",
    "\n",
    "Let’s now have a look at the data types in our ndarray. We can find this in the `dtype` attribute that is part of the ndarray data type, something that is known automatically for this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8573f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmpdata.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b102c90",
   "metadata": {},
   "source": [
    "Our data our floating point values with 64-bit precision. There are some exceptions, but 99% of all NumPy arrays will have the same dataset.\n",
    "\n",
    "Now lets check how many dimensions there are using `ndim` and how many rows and columns we have using `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dimensions:', tmpdata.ndim)\n",
    "print('shape:', tmpdata.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb4b7148",
   "metadata": {},
   "source": [
    "We have 51 rows of data and 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f29e6",
   "metadata": {},
   "source": [
    "### 1.4 Indexing our array\n",
    "\n",
    "Like lists, arrays can be indexed and sliced using those index values. Let's look at our data again. and focus on the data in third row and first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f346578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmpdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b8b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmpdata[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd054306",
   "metadata": {},
   "source": [
    "`tmpdata[2,0]` gives us the value of the data in the third row (which is row 2 in python because python indexing starts at 0), and first column. \n",
    "\n",
    "We can also use ranges of raws and columns using `:`. To get the first 10 rows in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdata[:10, 0] #here, we get all the rows up to, but not including, index 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3055755",
   "metadata": {},
   "source": [
    "The column headers for this dataset were YEARMONTHDAY, TAVG, TMAX, and TMIN. Let's just extract all the values from a given column to make these data easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2e096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = tmpdata[:,0]\n",
    "print(\"dates:\", date)\n",
    "tavg = tmpdata[:,1]\n",
    "tmax = tmpdata[:,2]\n",
    "tmin = tmpdata[:,3]\n",
    "print(\"min temps:\", tmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d266a91",
   "metadata": {},
   "source": [
    "Remember those magic commands. We can see all the data types we have defined at this point using the `%whos` magic command. When we do this, we might realize that it is v. foolish - even though this is a small file - to be storing these data that have no precision past a decimal as floating point, so let's at least convert the data column into int data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4af02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%whos\n",
    "\n",
    "date = date.astype('int')\n",
    "\n",
    "print(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffab9fe",
   "metadata": {},
   "source": [
    "### 1.5 Basic data calculations\n",
    "\n",
    "Numpy arrays have a set of attributes and methods to make calculations using data. Useful methods include, `mean()`, `median()`, `min()`, `max()`, and `std()`. \n",
    "\n",
    "Let's find the average temperature it's been in Richmond in 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a71bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tavg.mean()) #the historical average is around 37 deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b063c9",
   "metadata": {},
   "source": [
    "QUICK NOTE: We can do the same calculation on the big dataset by summarizing across an axis. axis = 0 = sum vertical axis, downwards, over all the rows in a column, axis = 1 = summarizing across the horizontal axis, across-words, over all the columns in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(suppress=True) # only toggle this on if you hate scientific notation as much as Prof Spera\n",
    "print(np.mean(tmpdata, axis=0)) # this will print the average date, averge temp, min temp and max temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a979f",
   "metadata": {},
   "source": [
    "People love numpy because it is super easy to do calculations. Remember back in lesson 1 where we had to figure out how to take one value in Farenheit and conver it to Celsius. Well, now that we have numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average RVA temp in F:\", tavg)\n",
    "\n",
    "tavg_C = (tavg - 32) / (9/5)\n",
    "\n",
    "print(\"average RVA temp in C:\", tavg_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d797ecd",
   "metadata": {},
   "source": [
    "### 1.6 Filtering data and using masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e8cbd",
   "metadata": {},
   "source": [
    "We can also filter data based on certain criterion. Let's say we wanted to know which days had average temps above 60 F/15 C in 2024, and then jusn January. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800ddf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warmTemps = tavg_C[tavg_C > 15]\n",
    "print(warmTemps)\n",
    "\n",
    "warmTempsJan = tavg_C[(tavg_C > 15) & (date < 20240201)]\n",
    "print(warmTempsJan) #fun! They were all in January\n",
    "print(\"There were\", len(warmTempsJan), \"days in January w average temps above 15 C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca16c2",
   "metadata": {},
   "source": [
    "It's more likely that instead of filtering data, you'll want to mask it. So, what if we want to identify the dates w. temps above 15C and keep only those dates in all of our other data columns. To do that, we'll use a mask array. \n",
    "\n",
    "A mask array is basically a boolean (True/False) array that can be used to take a subset of data from other data. So, instead of extracting w_temps directly, we'll first indentify where those elements in `tavg_C` are greater than 15C (`True`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ff15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmTempsMask = tavg_C > 15\n",
    "print(warmTempsMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f9eb1",
   "metadata": {},
   "source": [
    "Now we can use this mask on other columms of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmTempDates = date[warmTempsMask]\n",
    "print(warmTempDates) # cute lil Jan heat wave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7cefc8",
   "metadata": {},
   "source": [
    "### 1.7 Removing missing and bad data\n",
    "\n",
    "In some cases, a data file might contain missing values or values that cannot be read. These may be replaced by `nan` values when you look at your data. nan stands for “not a number”, and often we want to get rid of these things.\n",
    "\n",
    "Let’s consider a case where we have an array `badData` that is full of zeros, has the same size as `date` and the other arrays from our data file, and the first 5 rows have `nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dab08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some bad data\n",
    "badData = np.zeros(len(date))\n",
    "badData[:5] = np.nan\n",
    "print(badData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189fe8",
   "metadata": {},
   "source": [
    "If we wanted to include values for the date column that only correspond to locations in `badData` where we do not have a nan value, we can use the isfinite() function in NumPy. `isfinite()` checks to see if a value is defined (i.e., is not nan or infinite (inf)). \n",
    "\n",
    "So, we'll make a mask to find where the data is `finite` and only pull the dates associated with the good data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee451993",
   "metadata": {},
   "outputs": [],
   "source": [
    "badDataMask = np.isfinite(badData)\n",
    "print(badDataMask)\n",
    "goodDates = date[badDataMask]\n",
    "print(goodDates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ac3b3",
   "metadata": {},
   "source": [
    "### 1.8 Re-creating and saving an array\n",
    "\n",
    "We've mostly worked with single columns that we spliced after bringin in our temperature data. We can create the 2d data structure by stacking these columns back together. Let's pull together our `date` and `tavg_C` columns in a new array called `tempdata_C`. We'll use the `vstack()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286b6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempdata_C = np.vstack((date,tavg_C))\n",
    "print(tempdata_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7260293",
   "metadata": {},
   "source": [
    "Something looks weird here. Let's invsetigate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9a2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tempdata_C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce52ff",
   "metadata": {},
   "source": [
    "It looks like there are two rows and 51 columns. The columns and rows need to be flipped. We can do this using `transpose()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata_C = np.transpose(tempdata_C)\n",
    "print(tempdata_C.shape)\n",
    "print(tempdata_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d87a7",
   "metadata": {},
   "source": [
    "Now that our data looks good, we can save it using `savetxt()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('rva_temps_C.csv', tempdata_C, delimiter=',') #check to see if it saved!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22333a",
   "metadata": {},
   "source": [
    "## Knowledge Check\n",
    "Find the average mininum temperature and average maximum temperature during the first week of Feburary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba844940",
   "metadata": {},
   "source": [
    "# 2. Matplotlib\n",
    "\n",
    "Python has a **ton** of useful [libraries for plotting](https://rougier.github.io/python-visualization-landscape/landscape-colors.png). Matplotlib is probably the most widely used. The *cooler* [Seaborn](https://seaborn.pydata.org/) is built a top of Matplotlib. \n",
    "\n",
    "Matplotlib used to have a 'basemap' toolkit for making maps, but that's being depreciated for [Cartopy](https://scitools.org.uk/cartopy/docs/latest/) which we'll briefly tough on below.\n",
    "\n",
    "[Boken](https://docs.bokeh.org/en/latest/), [Plotly](https://plotly.com/python/), and [Dash](https://plotly.com/dash/) are fancy.\n",
    "\n",
    "And, if you love ggplot2, python has it's own [ggplot](https://yhat.github.io/ggpy/). \n",
    "\n",
    "## 2.1 Plotting basics\n",
    "There are a bunch of different types of plots:\n",
    "* [Bar chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)\n",
    "* [Histogram](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)\n",
    "* [Scatter plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html)\n",
    "* [Line chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html)\n",
    "* [Pie chart](https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_features.html)\n",
    "* [Violin chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.violinplot.html) # a better box plot\n",
    "* [Dendrogram](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)\n",
    " \n",
    "Most - if not all - of these plots have common elements. The figure hyperlinked [here](https://geo-python-site.readthedocs.io/en/latest/_images/basic-elements-of-plot.png) has a lot of the basic plot elements. \n",
    "\n",
    "Some common terms are:\n",
    "* *axis* - axes of graph (x, y, z if you're extra)\n",
    "* *title* - plot title\n",
    "* *label* - name of axis (xlabel or ylabel)\n",
    "* *legend* - plot legent\n",
    "* *tick label* - text/values represented on the axis\n",
    "* *symbol* - symbol for data points (on a scatter plot usually) that can presented w. different shapes and colors\n",
    "* *size* - size of a point on a scatter plot OR text sizes on a plot\n",
    "* *line style* - how the line should be drawn: solid, dashed, those stars\n",
    "* *line width* - width of line\n",
    "* *alpha* - transparency level of a filled element on a plot: 0 = fully transparent, 1 = fully opaque \n",
    "* *ticks* - tick marks\n",
    "* *annotation* - text added to a plot\n",
    "* *padding* - distance between an axis/tick label and axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893383cc",
   "metadata": {},
   "source": [
    "## 2.2 Loading and manipulating our data\n",
    "\n",
    "We need to import matplot lib, and we're going to use our dataset from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad9ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "filepath = \"/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/RVA_janfeb2024.csv\"\n",
    "data = np.genfromtxt(filepath, skip_header=5, delimiter=',')\n",
    "print(data)\n",
    "\n",
    "#I'm going to subset the data to just january\n",
    "data=data[:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We did all of this in lesson one, but I just added TS to designate\n",
    "# that it's a longer time series\n",
    "date = data[:,0]\n",
    "tavg = data[:,1]\n",
    "tmax = data[:,2]\n",
    "tmin = data[:,3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0d4fc",
   "metadata": {},
   "source": [
    "## 2.3 Plotting\n",
    "\n",
    "Plots are automatically displayed in Jupyter notebooks, so you don't need plt.show(), but you need that if not in a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = date\n",
    "y = tavg\n",
    "plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece533f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let's make our graph better\n",
    "plt.plot(x, y, 'ro--')\n",
    "plt.title('RVA temperatures Jan 2024')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1adc4e",
   "metadata": {},
   "source": [
    "Now we see our temperature data as a red dashed line with circles showing the data points. This comes from the additional `ro--` used with plt.plot(). In this case, `r` tells the plt.plot() function to use red [color](https://matplotlib.org/stable/gallery/color/named_colors.html), `o` tells it to show circles at the [points](https://matplotlib.org/1.4.1/api/markers_api.html), and `--` says to use a dashed line. You can use help(plt.plot) to find out more about formatting plots, OR, click on [this link](https://matplotlib.org/1.4.1/api/axes_api.html#matplotlib.axes.Axes.plot) to see all of the great documentation.\n",
    "\n",
    "### Embiggening\n",
    "\n",
    "While the plot sizes we’re working with are OK, you can display them to be any size you want in in Jupyter notebooks. To set the default plot size to be larger, simply run the Python code in a new cell below.\n",
    "\n",
    "```python\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "```\n",
    "That would set the default plot size to be 12 inches wide by 6 inches tall. You can run than and then rerun any of the plotting cells and see what happens.\n",
    "\n",
    "### Text labels\n",
    "If you want to add text to plots, you can do that using `plt.text()`.\n",
    "\n",
    "```python\n",
    "plt.text(20240126, 72, 'Too hot')\n",
    "```\n",
    "\n",
    "This will display the aforementioned text at the location `x = 20140126` (i.e., Jan 26, 2024), at `y = 72`, on the plot. We’ll see how to do this in a live example in just a second. With our approach to plotting thus far (we'll see another approach in Section 2.5), the commands related to an individual plot should all be in the same Python cell.\n",
    "\n",
    "### Changing the axis ranges\n",
    "\n",
    "We can change the plot axes using `plt.axis()`\n",
    "```python\n",
    "plt.axis([20240101, 20240131, 20, 80])\n",
    "```\n",
    "\n",
    "The format for `plt.axis()` is `[xmin, xmax, ymin, ymax]` in square brackets (because it's a list!). Let's put this together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21327325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'ro--')\n",
    "plt.title('RVA temperatures Jan 2024')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°F)')\n",
    "plt.text(20240126, 72, 'Too hot')\n",
    "plt.axis([20240101, 20240131, 20, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9b8ea",
   "metadata": {},
   "source": [
    "## 2.4 Customizing Plots\n",
    "\n",
    "We don't need to use numpy data or pandas data or even text data to create plots. We'll work with two lists to learn some of the myriad ways we can customize our plots.\n",
    "\n",
    "We're going to look at average monthly precipitation in Richmond between 1991 and 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9af5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists using data found here: \n",
    "# https://www.weather.gov/media/akq/climateRECORDS/RIC_Climate_Records.pdf\n",
    "\n",
    "rva_pcp = [3.21, 2.61, 4.0, 3.18, 4.0, 4.64, 4.37, 4.9, 4.61, 3.39, 3.06, 3.51]\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "plt.plot(months, rva_pcp)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddaac7f",
   "metadata": {},
   "source": [
    "Note that the output displays the object type as well as the unique identifier (or the memory location) for the figure.\n",
    "\n",
    "You can hide this information from the output by adding plt.show() - or commenting it out above - as the last line you call in your plot code.\n",
    "\n",
    "#### Let's get customizing. \n",
    "By default, plt.plot creates a line plot. This is not an ideal situation for plotting precipitation. \n",
    "\n",
    "What about a scatter plot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb3188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(months,rva_pcp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e470dd",
   "metadata": {},
   "source": [
    "Okay but this is useless for precipitation too. Let's make a bar chart instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0dace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, rva_pcp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e928b87",
   "metadata": {},
   "source": [
    "Great, let's add a title and axes like we learned to above but with a fancy line break designated by `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, rva_pcp)\n",
    "\n",
    "plt.title('Average Monthly Precipitation in RVA\\n1991-2020')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation\\n(inches)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb1b4d",
   "metadata": {},
   "source": [
    "Now let's adjust the transparency using `alpha` and color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, \n",
    "        rva_pcp, \n",
    "        color = 'dodgerblue', \n",
    "        edgecolor = 'darkslateblue', \n",
    "        alpha = 0.25)\n",
    "\n",
    "plt.title('Average Monthly Precipitation in RVA\\n1991-2020')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation\\n(inches)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1602903",
   "metadata": {},
   "source": [
    "#### Saving your plots\n",
    "\n",
    "Saving plots created using Matplotlib done several ways. The recommendation for use outside of Jupyter notebooks is to use the `plt.savefig()` function. When using `plt.savefig()`, you simply give a list of commands to generate a plot and list `plt.savefig()` with some parameters as the last command. The file name is required, and the image format will be determined based on the listed file extension.\n",
    "\n",
    "Matplotlib plots can be saved in a number of useful file formats, including PNG, PDF, and EPS. PNG is a nice format for raster images, and EPS is probably easiest to use for vector graphics. Let’s check out an example and save our lovely bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19aa040",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, \n",
    "        rva_pcp, \n",
    "        color = 'dodgerblue', \n",
    "        edgecolor = 'darkslateblue', \n",
    "        alpha = 0.25)\n",
    "\n",
    "plt.title('Average Monthly Precipitation in RVA\\n1991-2020')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation\\n(inches)')\n",
    "plt.savefig('rva_month_pcp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bee94",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "Using the temperature data from the numpy section, plot the average daily temperature in January 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9491c",
   "metadata": {},
   "source": [
    "## 2.5 Subplots\n",
    "\n",
    "If we wanted to level up, we could use subplots. Earlier we said that everything needed to be in the same Jupyter notebook cell block if we wanted it to all plot together. But, that wasn't giving matplotlib enough credit. \n",
    "\n",
    "Matplotlib uses an object oriented approach to plotting. This means that plots can be built step-by-step by adding new elements to the plot.\n",
    "\n",
    "There are two primary objects associated with a matplotlib plot:\n",
    "* `figure` object: the overall figure space that can contain one or more plots.\n",
    "* `axis` objects: the individual plots that are rendered within the figure.\n",
    "\n",
    "You can think of the figure object as your plot canvas. You can think about the axis object as an individual plot. See [this image](https://www.earthdatascience.org/images/earth-analytics/plot-data/fig-1-plot.png).\n",
    "\n",
    "A figure can hold one or more axis objects. This structure allows you to create figures with one or more plots on them.\n",
    "\n",
    "To create a plot using matplotlib’s object oriented approach, you first create the figure (which you can call `fig`) and at least one axis (which you can call `ax`) using the `subplots()` function from the pyplot module:\n",
    "\n",
    "`fig, ax = plt.subplots()`\n",
    "\n",
    "Notice that the `fig` and `ax` are created at the same time by setting them equal to the output of the `pyplot.subplots()` function. As no other arguments have been provided, the result is a figure with one plot that is empty but ready for data.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b094324",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure and one plot (axis object) \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf7beb",
   "metadata": {},
   "source": [
    "This format comes in handy, particularly, when working w. [multiplot figures](https://www.earthdatascience.org/images/earth-analytics/plot-data/fig-4-plots.png).\n",
    "\n",
    "Note: In the example above, `fig` and `ax` are variable names for the figure and axis objects. You can call these items whatever you want. For example, you might see f, ax or fig, axis1 used.\n",
    "\n",
    "When adding more than one axis object, it is good practice to give them distinct names (such as `ax1` and `ax2`), so you can easily work with each `axis` individually.\n",
    "\n",
    "You will need to provide new arguments to `plt.subplots` for the layout of the figure: number of rows and columns:\n",
    "\n",
    "`plt.subplots(1, 2)`\n",
    "\n",
    "In this example, 1, 2 indicates that you want the plot layout to be 1 row across 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8631754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure with two plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dba7ec",
   "metadata": {},
   "source": [
    "Conversely, (2, 1) indicates that you want the plot layout to be 2 rows across one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fa3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure with two plots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf0a28",
   "metadata": {},
   "source": [
    "A key benefit of the matplotlib object oriented approach is that each axis is its own object and can be customized independently of the other plots in the figure.\n",
    "\n",
    "Let's make a subplot with some seasonal minimum temperature data from Acadia Natioanl Park from 1950-2021 that Prof Spera has worked with.\n",
    "The data files are in the `.../resources/Lesson4` directory.\n",
    "* djf_tmin_acadia.csv\n",
    "* mam_tmin_acadia.csv\n",
    "* jja_tmin_acadia.csv\n",
    "* son_tmin_acadia.csv\n",
    "\n",
    "Check out the data before you load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef74f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# file paths\n",
    "djf_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/djf_tmin_acadia.csv\"\n",
    "mam_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/mam_tmin_acadia.csv\"\n",
    "jja_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/jja_tmin_acadia.csv\"\n",
    "son_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/son_tmin_acadia.csv\"\n",
    "\n",
    "# get time series data\n",
    "djfTS = np.genfromtxt(djf_file, skip_header=1, delimiter=',')\n",
    "mamTS = np.genfromtxt(mam_file, skip_header=2, delimiter=',') \n",
    "jjaTS = np.genfromtxt(jja_file, skip_header=2, delimiter=',')\n",
    "sonTS = np.genfromtxt(son_file, skip_header=2, delimiter=',')\n",
    "\n",
    "# turn the dates into integers\n",
    "years = (djfTS[:,0]).astype(int)\n",
    "\n",
    "# pull minimum temperature info from each dataset\n",
    "djf_tmin = djfTS[:,1]\n",
    "mam_tmin = mamTS[:,1]\n",
    "jja_tmin = jjaTS[:,1]\n",
    "son_tmin = sonTS[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357d537",
   "metadata": {},
   "source": [
    "Lets plot the seasons separately, quickly, just to get a feel for what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d2bc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(djf_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4d42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mam_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(jja_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99aafb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(son_tmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb67d4",
   "metadata": {},
   "source": [
    "Okayyy, let's make these subplots.  First, we can create a 2x2 panel for our visualization using Matplotlib’s `subplots()` function where we specify how many rows and columns we want to have in our figure. We can also specify the size of our figure with `figsize` parameter as we have seen earlier with pandas. Figsize takes the width and height values (in inches!) as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a013162",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd84d2",
   "metadata": {},
   "source": [
    "You can see that as a result we have now a list containing two nested lists where the first one contains the axis for column 1 and 2 on row 1 and the second list contains the axis for columns 1 and 2 for row 2.\n",
    "\n",
    "We can split these axes into their own variables so it is easier to work with them.\n",
    "`\n",
    "ax11 = axes[0][0]\n",
    "ax12 = axes[0][1]\n",
    "ax21 = axes[1][0]\n",
    "ax22 = axes[1][1]\n",
    "`\n",
    "After running that, we have four variables for our plot axes that we can use for the different panels in our figure. We will use them to plot the seasonal data. Let’s begin by plotting the seasons, and use different colors for the lines and specify the y-axis range to be the same for all subplots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba06c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax11 = axes[0][0]\n",
    "ax12 = axes[0][1]\n",
    "ax21= axes[1][0]\n",
    "ax22 = axes[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034938b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot line width\n",
    "line_width = 1\n",
    "\n",
    "# Plot data\n",
    "ax11.plot(years, djf_tmin, c=\"slategrey\", lw=line_width)#, set_ylim=([min_temp, max_temp]))\n",
    "ax12.plot(years, mam_tmin,  c=\"orchid\", lw=line_width)#, ylim=[min_temp, max_temp])\n",
    "ax21.plot(years, jja_tmin, c=\"olivedrab\", lw=line_width)#, ylim=[min_temp, max_temp])\n",
    "ax22.plot(years, son_tmin, c=\"orangered\", lw=line_width)#, ylim=[min_temp, max_temp])\n",
    "\n",
    "# Set figure title\n",
    "fig.suptitle(\"Average annual season temperature at \\nAcadia National Park, Maine\")\n",
    "\n",
    "# Rotate the x-axis labels so they don't overlap\n",
    "plt.setp(ax11.xaxis.get_majorticklabels(), rotation=20)\n",
    "plt.setp(ax12.xaxis.get_majorticklabels(), rotation=20)\n",
    "plt.setp(ax21.xaxis.get_majorticklabels(), rotation=20)\n",
    "plt.setp(ax22.xaxis.get_majorticklabels(), rotation=20)\n",
    "\n",
    "# Axis labels\n",
    "ax11.set_ylabel(\"Temperature [°C]\")\n",
    "ax21.set_ylabel(\"Temperature [°C]\")\n",
    "\n",
    "# Season label text\n",
    "# The first to numbers are where on the graph you want to put the text\n",
    "ax11.text(2010, -8, \"Winter\")\n",
    "ax12.text(2010, 0.5, \"Spring\")\n",
    "ax21.text(2010, 12.5, \"Summer\")\n",
    "ax22.text(2010, 6.5, \"Autumn\")\n",
    "# Display the figure\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e42372",
   "metadata": {},
   "source": [
    "FUN!\n",
    "\n",
    "If you run stats on these data, you'd see a statisically significant increase in minimum temperatures in fall, winter, and summer in Acadia. Nothing is happening in the spring!\n",
    "\n",
    "Fall nights are about 1.2°C (2.1°F) warmer on average now than 1950.\n",
    "Winter nights are about 1.4°C (2.5°F) warmer on average now than in 1950.\n",
    "And summer nights are about 1.6°C (2.9°F) warmer on average now than in 1950.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91992c",
   "metadata": {},
   "source": [
    "# Cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9bc0e",
   "metadata": {},
   "source": [
    "Cartopy is one of many packages that focuses on geospatial data. This means it can be used for plotting data on a map, but it can also be used for plotting geographical images such as sections of a Google map. \n",
    "\n",
    "Like Matplotlib, Cartopy has several different modules. We will be working with two important modules in this tutorial: `crs` and `feature`. \n",
    "\n",
    "`crs` is the basic map-making module that creates the coordinates that we want. \n",
    "`feature` allows us to add coastlines, borders, oceans, and other important distinctions to our maps.\n",
    "\n",
    "More info about Cartopy can be found [here](https://scitools.org.uk/cartopy/docs/latest).\n",
    "\n",
    "**Important: Before we move on, we have to change conda environments because cartopy is a tricky package. At the top of the page, click 'Kernel'>'Change kernel'>'qgis.' If people are really interested in why we have to do this, we can chat post-spring-break about conda environemnts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from cartopy import crs, feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd66fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we'll be using ozone data\n",
    "data = pd.read_csv('/scratch/myang_shared/lab/PythonBootcamp/Sp24/resources/Lesson4/july20_ozone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8cda91",
   "metadata": {},
   "source": [
    "Examine the data. What are the column names? What's the shape and size? Etc.\n",
    "\n",
    "Now let's pull some stuff together from a bunch of previous lessons to manipulate the data and make sure we're doing what we want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba0c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's deal with the dates\n",
    "dates = pd.to_datetime(data.loc[:, 'Date Local'])\n",
    "\n",
    "# add the dattimes back to the dataframe\n",
    "data['datetimes'] = dates\n",
    "\n",
    "# and now just double check that we did it write\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1d80c",
   "metadata": {},
   "source": [
    "Let's look at some trends over time using the super handy `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ea7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['Date Local'][0]))\n",
    "print(type(data['datetimes'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad02f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_o3 = data.filter(items=['Ozone (ppm)', 'datetimes']).groupby(data['datetimes'].dt.day).mean()\n",
    "daily_avg_o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plot\n",
    "y=daily_avg_o3['Ozone (ppm)']\n",
    "x=daily_avg_o3.index\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Day of Month')\n",
    "plt.ylabel('Ozone (ppm)')\n",
    "plt.title('July Daily Average Ozone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf976e5",
   "metadata": {},
   "source": [
    "This plot is telling us that the average ozone concentration across the entire United States fluctuates by less than 10 ppb during the month of July. But what is happening at specific locations? Can we zoom in to an area to better understand how air quality is changing there?\n",
    "\n",
    "Let's look specifically at Massachusetts. (Virginia was boring.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9190f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ma = data.loc[data['State Name']=='Massachusetts']\n",
    "ma\n",
    "\n",
    "ma_avg_o3 = ma.filter(items=['Ozone (ppm)', 'datetimes']).groupby(ma['datetimes'].dt.day).mean()\n",
    "\n",
    "y_ma = ma_avg_o3['Ozone (ppm)']\n",
    "x_ma = ma_avg_o3.index\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(x_ma,y_ma)\n",
    "plt.xlabel('Day of Month')\n",
    "plt.ylabel('Ozone (ppm)')\n",
    "plt.title('July Daily Average Ozone in Massachusetts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720269f0",
   "metadata": {},
   "source": [
    "Okay, it seems like there is something else going on in Massachusetts. We can assume ozone, then, varies in time and space. Let's make a map to see which areas in VA have high concentrations of ozone and which have low concentrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d88f12",
   "metadata": {},
   "source": [
    "## Making a map\n",
    "\n",
    "We generally need to follow the same steps to make a map:\n",
    "* 1. Indentify the coordinates of your region of interest (ROI)\n",
    "* 2. Make a grid on your coordinates of interest\n",
    "* 3. Select a map project\n",
    "* 4. Create a pyplot figure using your grid and map project\n",
    "* 5. Add the relevant features to your figure\n",
    "* 6. Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b383662",
   "metadata": {},
   "source": [
    "### 1. Indentify the coordinates of your ROI\n",
    "\n",
    "Sometimes, your data will have a pre-made grid of the latitude and longitude coordinates for you. This makes it really easy. In other cases, you might need to decide on the coordinates yourself. Our data does have latitude and longitude coordinates, but it does not tell us the size of the grid we want. We can use our latitude and longitude data to make an appropriately sized grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41626ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latmin = ma['Latitude'].min()\n",
    "latmax = ma['Latitude'].max()\n",
    "lonmin = ma['Longitude'].min()\n",
    "lonmax = ma['Longitude'].max()\n",
    "print('Lat Range: %.4f - %.4f' % (latmin,latmax))\n",
    "print('Lon Range: %.4f - %.4f' % (lonmin,lonmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a6ad5",
   "metadata": {},
   "source": [
    "Now that we know our max/min - we can make a box around our data. I like adding a little bit of a spatial buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae69702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffered lats and lons\n",
    "latmin = 41\n",
    "latmax = 43\n",
    "lonmin= -74\n",
    "lonmax = -69.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7e092",
   "metadata": {},
   "source": [
    "### 2. Make a grid\n",
    "\n",
    "This step will vary depending on the type of data you are plotting. We will be making a simple dot map, so we basically need to set a max and min range for our map's box size. If we were using gridded data that covered the whole area, like satellite data or a model output, we would need to make a meshgrid that had a lat and lon coordinate pair for each grid cell. Prof Spera can write up something on this if people are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [lonmin, lonmax, latmin, latmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffbbb5",
   "metadata": {},
   "source": [
    "### 3. Select a map projection.\n",
    "We also need to decide on a map projection. A map projection tells you how the map will be displayed. If you've taken Geog/Envs 260, you'll hopefully have heard all about projections. There's more info [here](https://scitools.org.uk/cartopy/docs/latest/crs/projections.html.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection\n",
    "proj = crs.PlateCarree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cfd7e",
   "metadata": {},
   "source": [
    "### 4. Create a Figure\n",
    "\n",
    "Let's try and put everything together in a pyplot figure to set up our map background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "# ax.set_extent([lonmin,lonmax,latmin,latmax],crs.PlateCarree())\n",
    "ax.set_extent(extent)\n",
    "# # add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defabec",
   "metadata": {},
   "source": [
    "### 5. Add relevant figures. \n",
    "Let's make sure this is in the right place by adding details like rivers, state borders, etc.\n",
    "\n",
    "Note: If you are getting DownloadWarnings but the figure does appear, then don't worry. If you rerun the cell, you will see the DownloadWarning has disappeared. If you add new features, you will get a new warning, but it'll go away the next time you use that feature. When Cartopy was initially installed, it didn't download all the different map features with it. So it has to download them the first time you want to use those features in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "# IF YOU GET DOWNLOAD WARNINGS, JUST WAIT THEM OUT. THINGS WILL PROCESS. \n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6da898",
   "metadata": {},
   "source": [
    "### 6. Plot the data\n",
    "\n",
    "The daily ozone data has lat and lon coordinates. But we have data for every day in the month of July, which is too much to plot all at once. Instead, let's pick just one day and plot that data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234780aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get data from July 1\n",
    "july_1=ma[ma['datetimes']=='2020-07-01']\n",
    "\n",
    "july_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lat, lon and y-data\n",
    "lats = july_1['Latitude']\n",
    "lons = july_1['Longitude']\n",
    "o3 = july_1['Ozone (ppm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fedf79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "\n",
    "# ax.add_feature(feature.RIVERS)\n",
    "\n",
    "# plot the data -- note, we use plt.scatter to add data on top of the map!\n",
    "plt.scatter(lons,lats,s=50,c=o3)\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5, pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b18730",
   "metadata": {},
   "source": [
    "Wow, so seems like southeastern Mass has higher concentrations of ozone than the rest of the state. But, if you remember from the line graph above, ozone was highest across the state on July 19. Let's see if we have the same spatial pattern then as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60103ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select monitor data from July 31st\n",
    "july19 = ma.loc[ma['datetimes'] == '2020-07-19']\n",
    "\n",
    "# get the lat, lon, and y-data\n",
    "lats = july19['Latitude']\n",
    "lons = july19['Longitude']\n",
    "o3 = july19['Ozone (ppm)']\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "# ax.add_feature(feature.RIVERS)\n",
    "# plot the data -- note, we use plt.scatter to add data on top of the map!\n",
    "plt.scatter(lons,lats,s=50,c=o3)\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5, pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6b7b1",
   "metadata": {},
   "source": [
    "Totally different pattern! Amtospheric chemistry changes in space & time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee877f",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "Map a state that isn't Massachusetts using the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6932945",
   "metadata": {},
   "source": [
    "### A projection deep dive (skip this section if you're not interested)\n",
    "To evaluate the importance of projections, we really need to look on a larger scale than the state level. Since our ozone data is for the entire US, let's look at the total area covered by the data.\n",
    "But remember, [projections](https://www.leventhalmap.org/digital-exhibitions/bending-lines/interactives/projection-face/) are essentially how we get a 3-d surface (the surface of the earth, which is a sphere), to a 2-d surface (a map). If you haven't taken Geog 260, see this [figure](https://media.licdn.com/dms/image/C4D12AQGszV4q-00Lew/article-inline_image-shrink_1500_2232/0/1634289520658?e=1712793600&v=beta&t=II_5VLlRGOnrkkU_dZwp6VOYR3q3gDdPwEUSNCPNBkQ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the min and max coordinates of monitors in our dataset?\n",
    "latmin = data['Latitude'].min()\n",
    "latmax = data['Latitude'].max()\n",
    "lonmin = data['Longitude'].min()\n",
    "lonmax = data['Longitude'].max()\n",
    "print('Lat Range: %.4f - %.4f' % (latmin,latmax))\n",
    "print('Lon Range: %.4f - %.4f' % (lonmin,lonmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325fa8e",
   "metadata": {},
   "source": [
    "Let's go through our map-making steps but for the whole US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the coordinates\n",
    "# buffered lat/lon values\n",
    "latmin = 15\n",
    "latmax = 65\n",
    "lonmin = -60\n",
    "lonmax = -150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1861fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Make the grid\n",
    "# set the extents of our box\n",
    "extent = [lonmin,lonmax,latmin,latmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e332239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Select the map projection\n",
    "# first, we'll stick with PlateCarree\n",
    "proj = crs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a figure\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42aed0",
   "metadata": {},
   "source": [
    "Okay, it appears we have states but not countries. Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7cc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7548bd0",
   "metadata": {},
   "source": [
    "Does the US seem to be the right shape? Or do things look a bit flattened? That's what happens with PlateCarree, it flattens out the map. Let's try some other projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a800a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albers Equal Area projection\n",
    "proj = crs.AlbersEqualArea()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562cc73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d80a1",
   "metadata": {},
   "source": [
    "The Albers Equal Area projection is a conical projection, meaning it pretends the globe is actually a cone and uses a conical projection. Not great either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bceb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lambert Conformal. This projection is useful if you ever use CMAQ or WRF data\n",
    "proj = crs.LambertConformal()\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966716f",
   "metadata": {},
   "source": [
    "We're getting better. At least the US is nearly centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a9561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Robinson projection\n",
    "proj = crs.Robinson()\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b7c02",
   "metadata": {},
   "source": [
    "This projection is good if you're mapping most of the world. You can find all of cartopy's projections [here](https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html). \n",
    "\n",
    "We've examined a few projections. Let's see how this can affect the data. Let's stick w. Robinson just for kicks and pick just one random day to focus on, and plot all monitor locations just to prove another point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea54c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's map July 4th, 2020\n",
    "sel_date = data[data['datetimes'] == '2020-07-04']\n",
    "\n",
    "# get the lat, lon, and y-data\n",
    "lats = sel_date['Latitude']\n",
    "lons = sel_date['Longitude']\n",
    "o3 = sel_date['Ozone (ppm)']\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "# add data\n",
    "plt.scatter(lons,lats,s=10,c=o3)\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fa5ea",
   "metadata": {},
   "source": [
    "Wait! What happened? Where is the data? The lats, lons, and ozone variables definitely have values, so that isn't the problem. Why didn't any dots show up on the map?\n",
    "\n",
    "The answer is in the projection. We changed the map projection from Plate Carree to Robinson. But, we left the data in Plate Carree (flat) projection. In order to map our flat data onto a not-flat map, we need to transform it. This data + map being in the same projection gets a lot of people stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27c10c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "# add data\n",
    "plt.scatter(lons,lats,s=10,c=o3,transform=crs.PlateCarree()) # added transform here\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f515789",
   "metadata": {},
   "source": [
    "### Knowledge check\n",
    "\n",
    "Pick a different projection and plot the average July ozone across just the contiguous US (no Alaska, Hawaii, or Puerto Rico). Notice any interesting spatial patterns across the US?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a6ea6",
   "metadata": {},
   "source": [
    "## NetCDFS and XArray \n",
    "\n",
    "If you want to keep going...so when Profs Spera and Yang were mere grad students, when Vines was the original TikTok, the iPhoen 5s was released, and Gangham Style was sweeping the world, numpy was the way big datasets were dealt with. But now, there's a fancier, newer package, called `xarray` - which is essentially built upon `numpy` - and it is quite the treat for dealing with netcdfs and geotiffs, and basically any gridded dataset where each pixel value also has a lat/lon value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f572d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import some packages\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce888671",
   "metadata": {},
   "source": [
    "Because large gridded dataset files are huge, let's just download them directly.\n",
    "We can use a for loop to download more than one file, but let's work with one for right now. We'll be using NCEP's North American Regional Reanalysis (NARR) at the daily height of the planetary boundary layer (pbl) in 2023. More info [here](https://psl.noaa.gov/data/gridded/data.narr.html). The pbs is the lowest part of the atmosphere where winds are influened by friction and it's height is important for things like weather forecasting and air travel. \n",
    "\n",
    "When you run the cell below, you'll likely get a SerializationWarning. This warning is simply saying that Xarray is reading all instances of ± 9.96921e+36 as `not a number (nan)`. We can check the validity of this on the NCEP [info page](https://psl.noaa.gov/data/gridded/data.narr.html). On the right hand side under Missing Data, missing values are indeed replaced with ± 9.96921e+36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de296d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# link to the file in noaa's repository\n",
    "file = 'http://psl.noaa.gov/thredds/dodsC/Datasets/NARR/Dailies/monolevel/hpbl.2023.nc'\n",
    "# use xarray to open the file\n",
    "data = xr.open_dataset(file,engine='netcdf4')\n",
    "\n",
    "# print the data\n",
    "# this might take a hot sec.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a08219",
   "metadata": {},
   "source": [
    "Okay, fun! It doesn't look like a spreadsheet. Let's break this down.\n",
    "\n",
    "**Array Type**: The very first thing that is shown in the above print out is 'xarray.Dataset'. There are two main types of arrays that xarray can handle: DataArrays and Datasets. A Dataset is a collection of DataArrays. Imagine that a DataArray is a rubix cube. It is a 3D (or 2D or 4D or however shaped) array of data. A Dataset would therefore be a collection of rubix cubes. Imagine you ordered a shipment of 30 rubix cubes. Each individual rubix cube is a DataArray, and the box that all the cubes were shipped in is the Dataset. We can select one DataArray using its variable name. There are some data selection methods that only work on DataArrays, which is why it is important to distinguish between DataArrays and Datasets.\n",
    "\n",
    "**Dimensions**: The dimensions are the directions that the file has, or the names of the axes. There are four dimensions listed in this file: time, x, y, and nbnds. Since this is meteorological data, we can think of these as latitudes or rows and longitudes or columns. There are 277 y, which means there are 277 lines of latitude in the grid. There are 349 x, or 349 lines of longitude. The time dimension has 365 values. We selected daily means over a year. If we had selected data from 2020, the number would be 366 becayse leap year.\n",
    "\n",
    "**Coordinates**: Coordinates are labels for each step of a dimension. This particular file has three of the same coords as in dims: x, y, and time. However, nbnds is not in the coord list, and now there are lat and lon coords. Next to each coord is the number and name of the dimensions in that coord. Time, x, and y only have one dimension and those dimensions have the same name. Click on the piece of paper next to each of these coordinates. What does it say? In comparison, lat and lon have two dimensions: (y,x). This is because any point on a map will have a unique latitude and longitude combination. Each grid point in this Dataset will also have a unique latitude and longitude combination, which is made up of x and y values.\n",
    "\n",
    "**Data Variables**: These are the variables of interest. This is the actual data in your file. For example, there is `hpbl` that might be of interest to us. In some Datasets, the data variables have unusual names, which can make understanding the data difficult. Xarray is great because it allows you to have metadata for each data variable, which might help to explain the data a little more. Click on the picture of a piece of paper next to the `hpbl` variable name. What does it say? Some of the data variables have useful metadata under this piece of paper.\n",
    "\n",
    "**Indexes**: Indexes are not always in an Xarray Dataset. Dimensions and coords are more useful in Xarray than the indexes, but you might find Datasets that include them. In this case, it is the three dimensions of the data (x,y, time) with a pandas series of the values for each dimension that is listed in the coords.\n",
    "\n",
    "**Attributes**: Finally, Xarray has more metadata stored in the Attributes. Some of this information can be helpful, such as the lat and lon corners. Knowing the shape and map projection is important for properly formatting the data for visualization.\n",
    "\n",
    "If you are interested in knowing just the attributes or just the coordinates or just the dims of an Xarray DataArray, you can call this information specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88e36c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the dimensions of dataset\n",
    "data.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7b152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the coordinates of the dataset\n",
    "data.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92869d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the attributes of the dataset\n",
    "data.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b1729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the variables in the dataset\n",
    "data.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa01a9e",
   "metadata": {},
   "source": [
    "### Selecting and indexing data\n",
    "Earlier we said that DataArrays and Datasets are different. Indexing and selecting data is one of the places that distinguish DataArrays and Datasets. Right now, we have a Dataset. This is a collection of DataArrays. We can select one of these DataArrays from the whole Dataset using the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fa31e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a data array from our datset\n",
    "var = data['hpbl']\n",
    "\n",
    "# print the data\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6525e",
   "metadata": {},
   "source": [
    "Now that we have a DataArray, we can select the dimension of the data using the positions OR using names, so we can use either an integer or label. We'll try some examples.\n",
    "\n",
    "In terms of dimensions, the DataArray is set up `[time, x, y]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82b367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take the first time slice but all the values in the x and y dimension\n",
    "var[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac419cd3",
   "metadata": {},
   "source": [
    "We can also use `isel` (integer select) to get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ff8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take the first time slice using names & integers\n",
    "var.isel(time=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605ac3c",
   "metadata": {},
   "source": [
    "We can also use dictionaries and keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f010ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var[dict(time=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45873106",
   "metadata": {},
   "source": [
    "So, there are multiple ways to select & index data. You can only do this with DataArrays. Datasets are more complicated, and can only be indxed using dimension names, not positions.\n",
    "\n",
    "We can also slice our data. \n",
    "A slice is what it sounds like: it is a piece of the data that we are cutting out from the whole. slice(None, 3) says \"Cut a piece of this data, starting at the 0th position (None) and ending at the 3rd position (3).\" We used the dimension name \"y\" to tell xarray which dimension to index on. So y=slice(None,3) is saying \"Cut a piece of the data along the y dimension, starting at the 0th position and ending at the 3rd position.\" This is how we cut out the first 3 y's of the data.\n",
    "In the cell below, we print out the dimensions of the original data and of some sliced data. Do the dimensions printed match your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab73a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dims)\n",
    "print(data[dict(y=slice(None,30))].dims)\n",
    "print(data[dict(x=slice(25,100))].dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435f177",
   "metadata": {},
   "source": [
    "### Net CDF Data Viz\n",
    "\n",
    "This data is the height of the planteary boundary layer in meters above the surface. The dimensions of the data are x, y, and time. We could plot this data as rows (latitudes) and columns (longitudes) using a grid of 349 by 277 or we could make line plots of average temps over one of these dimensions.\n",
    "\n",
    "What if we wanted to know the average temperature along a latitude or longitude? Perhaps we have the hypothesis that PBL height is higher at lower latitudes closer to the equator. How would we test this hypothesis? We could take the mean of the data along the axis of interest.\n",
    "\n",
    "Since the PBL data is formatted in a 3D array, and we want to take the average along two of these dimensions to make a line plot of height versus dimension. If we want to know the average at each latitude, then we must take the mean along the longitude and time dimensions. If this is hard to visualize, think back to a rubix cube. We want to know the average at each point along the y-axis (the rows). In order to do this, we must smush the x-axis, so take the average of the columns.\n",
    "\n",
    "Once again, we can using different indexing methods in Xarray to accomplish the same task. Now let's plot the averages, this time using Xarray plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad8474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select the variableb\n",
    "hpbl = data['hpbl']\n",
    "\n",
    "hpbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the data over time\n",
    "hpbl_timeavg = hpbl.mean(axis=0)\n",
    "hpbl_timeavg.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35127dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the rows/latitudes using dimension names\n",
    "hpbl_lat = hpbl_timeavg.mean('x')\n",
    "hpbl_lat.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaef244",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "hpbl_lat.plot()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3361a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xarray will do it's best to label the axes \n",
    "# but we can make them better\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "degrees = 1 + hpbl_lat['y']/111139 # convert x to degrees latitude\n",
    "plt.plot(degrees,hpbl_lat)\n",
    "plt.title('Average Planetary Boundary Layer Height')\n",
    "# you can change the label data for your data\n",
    "\n",
    "plt.xlabel('Latitude (˚)',fontsize=12)\n",
    "plt.ylim((0,1000))\n",
    "plt.ylabel('Height (m)',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cfb02a",
   "metadata": {},
   "source": [
    "The planetary boundary layer height is higher at lower latitudes - in other words, the atmosphere is thicker closer to the equator. Why might that be? \n",
    "\n",
    "Also, what if we want to plot this gridded data on a map? We. Can. Do. It.\n",
    "You can find a bunch of fun data [here](https://www.ncei.noaa.gov/access/world-ocean-atlas-2018/) but let's look at sea surface temperature data from the summers between 2005-2017 from Argo float [buoys](https://argo.ucsd.edu/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e046a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy import crs, feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to the data\n",
    "file = 'https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/temperature/A5B7/1.00/woa18_A5B7_t15_01.nc'\n",
    "\n",
    "# why do we have to set decode_times = false here?\n",
    "# what happens if we don't?\n",
    "data = xr.open_dataset(file, engine='netcdf4', decode_times=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c010d5f",
   "metadata": {},
   "source": [
    "Let's select the data and then make a quick and dirty figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0a917",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = data['t_an']\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409048f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# basic contour plot using lat, lons, for \n",
    "# the first time stamp at the surface (depth = 0)\n",
    "plt.contourf(temp['lon'], temp['lat'], temp[0,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10c21b",
   "metadata": {},
   "source": [
    "Now that we've looked at the entire dataset area, we can zoom in on a particular section. There are a few ways to do this, but we'll practice the easiest first.\n",
    "\n",
    "The easiest method to zoom into an area on a map is to only plot that area with cartopy. This is fast and useful for making a map for presentations, but there are some downsides.\n",
    "\n",
    "* First, this method does not remove the rest of the data, it just hides it from our view. If you wanted to find the average chlorophyll-a concentration in the zoomed in area, you could not calculate it from the map because the rest of the data actually still exists.\n",
    "* Second, outliers in the data outside the zoomed in area might affect the colorbar scale of the displayed map. So you could have a map area with concentrations all below 20 mg/m 3, but a larger concentration elsewhere in the dataset will skew the colorbar scale and you won't be able to see the low concentrations clearly.\n",
    "* Finally, for really big datasets, it might take a while to plot. You're still technically plotting all the data, it just isn't displayed in the figure area. So if the dataset is really big, you're wasting time plotting data that you don't actually see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's choose an area of interest\n",
    "latmin = 37\n",
    "latmax = 45\n",
    "lonmin = -65\n",
    "lonmax = -75\n",
    "\n",
    "# set extent\n",
    "extent = [lonmin, lonmax, latmin, latmax]\n",
    "\n",
    "# set the projection - make sure it matches that of the dataset\n",
    "proj = crs.PlateCarree()\n",
    "print(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We mentioned this above w. the point data, but with\n",
    "# gridded data, you have to make a grid of the coordinates\n",
    "\n",
    "lats = temp['lat']\n",
    "lons = temp['lon']\n",
    "\n",
    "# make the gred\n",
    "XX,YY = np.meshgrid(lons,lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95418c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "im = plt.contourf(XX,YY,temp[0,0,:,:],cmap='turbo',transform=proj)\n",
    "plt.colorbar(im,orientation='horizontal',label='Temperature (˚C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b2676",
   "metadata": {},
   "source": [
    "What do you notice about this figure? What about the colorbar scale? What could make this figure better?\n",
    "\n",
    "The figure above has a colorbar scale that goes from -5 to 40 ˚C, even though the data in the figure does not seem to go this high or low. This is one of the problems with this plotting method. Your colorbar scale may be different if you used a different date of data.\n",
    "\n",
    "Instead of plotting all the data but hiding most of it, we can instead select a subsection of the data using slicing. This method takes a few more steps because you need to know the area of interest. However, there are several benefits such as being able to really focus on the actual area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d161ae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# slice the data using these limits\n",
    "subset = temp.sel(lat=slice(latmin,latmax),lon=slice(lonmax,lonmin))\n",
    "\n",
    "# check out the data and the change in dimensions\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6221db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to plot a subset of the data on the map, \n",
    "# we must make a grid of the coordinates\n",
    "# first, get a list of each coordinate\n",
    "lats = subset['lat']\n",
    "lons = subset['lon']\n",
    "\n",
    "# then make a grid\n",
    "XX,YY = np.meshgrid(lons,lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0957c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "im = plt.contourf(XX,YY,subset[0,0,:,:],cmap='turbo',transform=proj)\n",
    "plt.colorbar(im,orientation='horizontal',label='Temperature (˚C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8422a8fb",
   "metadata": {},
   "source": [
    "The code ran faster because we slided the data. \n",
    "But, we still have giant empty spaces because the data is at a 1 deg by 1 deg (100 km by 100 km) spatial resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08d4b3",
   "metadata": {},
   "source": [
    "If you want to try one more plot you can, if not, no big! Here we'll use annual average density on a quarter degree (1/4 deg ~ 25 km) grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff67509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file2 = 'https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/density/decav/0.25/woa18_decav_I00_04.nc'\n",
    "\n",
    "data2 = xr.open_dataset(file2,engine='netcdf4',decode_times=False)\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56454a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the data we want\n",
    "dens = data2['I_an'][0,0,:,:]\n",
    "dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e171725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our lats and lons again\n",
    "latmin = 37\n",
    "latmax = 45\n",
    "lonmin = -65\n",
    "lonmax = -75\n",
    "\n",
    "# get the subset\n",
    "subset = dens.sel(lat=slice(latmin,latmax),lon=slice(lonmax,lonmin))\n",
    "\n",
    "# set the extent of our box\n",
    "extent = [lonmin,lonmax,latmin,latmax]\n",
    "\n",
    "# set the right map projection\n",
    "proj = crs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3594bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to plot a subset of the data on the map, we must make a grid of the coordinates\n",
    "# first, get a list of each coordinate\n",
    "lats = subset['lat']\n",
    "lons = subset['lon']\n",
    "\n",
    "# then make a grid\n",
    "XX,YY = np.meshgrid(lons,lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0300968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "im = plt.contourf(XX,YY,subset,cmap='BuPu',transform=proj)\n",
    "plt.colorbar(im,orientation='horizontal',label='Density $(kg/m^{3})$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2934f11",
   "metadata": {},
   "source": [
    "Let's zoom out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = dens['lat']\n",
    "lons = dens['lon']\n",
    "\n",
    "XX,YY = np.meshgrid(lons,lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e242f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent([-180,180,-90,90])\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.LAND,color='grey',alpha=0.3)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "im = plt.contourf(XX,YY,dens,cmap='BuPu',transform=proj)\n",
    "plt.colorbar(im,orientation='horizontal',label='Density $(kg/m^{3})$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5edb83f",
   "metadata": {},
   "source": [
    "It appears that here things have a density of 0, which is impossible? Let's see what the minimum density is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0b86a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dens.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bfeb2",
   "metadata": {},
   "source": [
    "Okay, at least the minimum isn't actually zero, but it is really small. This highlights the importance of knowing your data. These density values we've been using are not absolute densities, they are sigma-t densities. They are the difference from  1000kg/m3, which is why we can have such small values. In reality, the density values should be 1000 + dens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c19229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent([-180,180,-90,90])\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.LAND,color='grey',alpha=0.3)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "im = plt.contourf(XX,YY,dens+1000,cmap='BuPu',transform=proj)\n",
    "plt.colorbar(im,orientation='horizontal',label='Density $(kg/m^{3})$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607b5af",
   "metadata": {},
   "source": [
    "We done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qgis]",
   "language": "python",
   "name": "conda-env-qgis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
