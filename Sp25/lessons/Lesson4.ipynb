{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59bd53e",
   "metadata": {},
   "source": [
    "# Python Packages  <a name='home' />\n",
    "\n",
    "**Table of Contents:**\n",
    "- <a href=#bookmark0>0. Overview on Modules</a> \n",
    "- <a href=#bookmark1>1. Numpy</a> \n",
    "- <a href=#bookmark2>2. Matplotlib</a> \n",
    "- <a href=#bookmark3>3. Cartopy</a> \n",
    "\n",
    "## Numpy, MatPlotLib, Cartopy, and Netcdfs/xarray <a name='bookmark0' />\n",
    "\n",
    "In Python, a package is a bundle of pre-built functions that adds to the functionality available in base Python. Base Python can do many things such as perform math and other operations. However, Python packages can significantly extend this functionality.\n",
    "\n",
    "You can think of a Python package as a toolbox filled with tools. The tools in the toolbox can be used to do things that you would have to otherwise hand code in base Python. These tasks are things that many people might want to do in Python, thus warranting the creation of a package. It doesn’t make sense for everyone to hard code everything.\n",
    "\n",
    "There are many different packages available for Python. Some of these are optimized for scientific tasks such as:\n",
    "* Statistics\n",
    "* Machine learning\n",
    "* Using geospatial data\n",
    "* Plotting & visualizing data\n",
    "* Accessing data programmatically\n",
    "\n",
    "Some important packages include: \n",
    "* **os:** handle files and directories.\n",
    "* **glob:** create lists of files and directories for batch processing.\n",
    "* **matplotlib:** plot data.\n",
    "* **numpy:** work with data in array formats (often related to imagery and raster format data).\n",
    "* **scipy:** work with many algorithms for doing scientific computing, e.g. statistical analyses.\n",
    "* **pandas:** work with tabular data in a DataFrame format.\n",
    "* **rasterio:** work with raster (image and arrays) data.\n",
    "* **geopandas:** work with vector format (shapefiles, geojson - points, lines and polygons) using a geodataframe format.\n",
    "* **cartopy:** plot and manipulate spatial data (raster and vector).\n",
    "\n",
    "### Python Packages Can Contain Modules\n",
    "Every Python package should have a unique name. This allows you to import the package using the name with the `import` command.\n",
    "\n",
    "For example, the command below imports the matplotlib package.\n",
    "\n",
    "```python\n",
    "import matplotlib\n",
    "```\n",
    "\n",
    "Packages often have modules (i.e. units of code) that each provide different functions and can build on each other. Stealing directly from this [StackOverflow answer](https://stackoverflow.com/questions/7948494/whats-the-difference-between-a-module-and-package-in-python), *Any Python file is a module, its name being the file's base name without the .py extension.\r\n",
    "A package is a collection of Python modules: while a module is a single Python file, a package is a directory of Python modules containing an additional __init__.py file, to distinguish a package from a directory that just happens to contain a bunch of Python scripts. Packages can be nested to any depth, provided that the corresponding directories contain their own __init__.py file.\r\n",
    "The distinction between module and package seems to hold just at the file system level. When you import a module or a package, the corresponding object created by Python is always of type module. Note, however, when you import a package, only variables/functions/classes in the __init__.py file of that package are directly visible, not sub-packages or module*s. \n",
    "\n",
    "The matplotlib package has a commonly used module called **pyplot**.  **Pyplot** makes it easier to quickly set up plots. You can import a specific module like **pyplot** by first calling the package name and then the module name - using . to separate the names like this:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot\n",
    "```\n",
    "\n",
    "But, the better way  import both packages and moduless, is to use an *alias*:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "````\n",
    "\n",
    "Aliases allows you to call functions from the imported package and/or module using the short name, rather than having to type out the full name of the packages and/or module each time that you want to call a function from i For numpy, we're important all of the scripts associated with that package. Matplotlib is huge, thus, we often only want to import the scripts associated with pyplot.t.\n",
    "\n",
    "Hot tip: You can get a list of the functions available in a package or module using `dir(np)`. A list of callable functions will appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993edf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dir(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dde8c",
   "metadata": {},
   "source": [
    "<a href=#home>Return to Top</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec89320",
   "metadata": {},
   "source": [
    "## 1. Numpy <a name='bookmark1' />\n",
    "\n",
    "Numpy arrays are a commonly used data structure in Python. You can think of arrays as a grid, or matrix.\n",
    "\n",
    "Like lists, numpy arrays are also composed of ordered values (called elements) and use indexing to organize and manipulate the elements in the numpy arrays. But, unlike lists, all elements in the array must be the same data type (i.e., all integers, floats, strings, etc). \n",
    "\n",
    "Numpy arrays can also have N dimensions (while lists, and tuples, etc only have one, and pandas dataframes have two). So think, raster stack. \n",
    "\n",
    "And, unlike lists, which you can just use in native python, you need packages to deal with arrays. Numpy is the most commonly-used package for arrays. And it is also the package that more sophisticated packages, like [xarray](https://xarray.dev/) and [rioxarray](https://corteva.github.io/rioxarray/stable/), are built off of.\n",
    "\n",
    "Arrays are defined like this `array()`. \n",
    "\n",
    "#### Key differences between lists and Numpy Arrays\n",
    "* Unlike a list, elements in a numpy array must be the same data type\n",
    "* Because of this, numpy arrays support arithmetic and other mathematical operations that run on each element of the array (e.g. element-by-element mutiplication). You cannot directly apply a numeric calculation to a list, and typically can only apply numeric calculations by applying the calculation through looping over each element.\n",
    "* Unlike a list, you can't remove or add elements to an array, though you can modify elements already in an array. If you add rows or columns, you will be creating a new array each time. \n",
    "* Numpy arrays can store data along N DIMENSIONS. This make numpy arrays super efficient if you're using a large dataset.\n",
    "\n",
    "### 1.1. Dimensionality of Numpy Arrays\n",
    "Numpy arrays can be\n",
    "* 1. 1-D composed of values along one dimension - resembling a list\n",
    "* 2. 2-D composed of rows of individual arrays with one or more columns - like a pandas data frame but just the values without headers.\n",
    "* 3. N-D composed of nested arrays with one or more dimensions. Prof Spera uses a lot of 3D datasets because there's a time dimension. A global daily precipitation dataset will have rows/columns with data points of precip values and then a third, z / [time dimension](https://xarray.pydata.org/en/stable/_images/dataset-diagram.png). Dr. Yang mostly works with 2D arrays, but there's functionality for N-d arrays, such as connecting latitude, longitude, time, and a genotype, for example.\n",
    "\n",
    "Brackets `[]` are used to assign the dimensions of a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd07b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 1-d array of average precipitation for Jan, Feb, and March in Boulder, CO in 2023\n",
    "avg_monthly_pcp = np.array([0.7, 0.75, 1.85])\n",
    "print(avg_monthly_pcp)\n",
    "print (type(avg_monthly_pcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2-d array of monthly precip Jan through Mar in 2002 and 2013\n",
    "pcp02_13 = np.array([\n",
    "    [1.07, 0.44, 1.50],\n",
    "    [0.27, 1.13, 1.72]\n",
    "])\n",
    "print(pcp02_13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfb2b6",
   "metadata": {},
   "source": [
    "### 1.2 Reading in a dataset\n",
    "Prof Spera is of the mind that one of the best ways to learn numpy is to manipulate real data. So let's have at it. First let's inspect the data, which is here in this directory: `/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/`. These data were downloaded from NOAA [here](https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00013740/detail).\n",
    "\n",
    "You can either look at the contents in the Terminal using some of our handy Linux commands. Or, in Jupyter Lab, navigate to the `Lesson4_2025/` folder and double click on RVA_janfeb2025.csv to quickly look at the data. \n",
    "\n",
    "Regardless of how you inspect the data, you should see a description of the data, some column/variable headings, and then some data itself. Let's load this into numpy. \n",
    "\n",
    "(Running the next code block will kick out an error - before reading on, can you make a guess as to why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d0641-f86c-40a1-b09f-6cc212172de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/RVA_janfeb2025.csv\"\n",
    "tmpdata = np.genfromtxt(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2d211",
   "metadata": {},
   "source": [
    "Note the metadata/header at the top of the file:\n",
    "\n",
    "    ```\n",
    "    \"Daily temperatures (mean, min, max) for Richmond, VA. Jan 1, 2025 - Feb 18, 2025\",,,\n",
    "    Datasource: NCDC Daily Data,,,\n",
    "    \"Station: USW00013740, Richmond Airport\",,,\n",
    "    ,,,\n",
    "    YEARMONTHDAY,TAVG,TMAX,TMIN\n",
    "    ```\n",
    "\n",
    "This part of the text file provides basic information about the file contents, while helpful to us, but is upsetting numpy. Remember, we only want the numpy elements to be the data themselves. Because all the data have to be the same data type, we only want the rows after this text block to be incorporated in the numpy array. Note also that the array needs to be a rectangle or square. \n",
    "\n",
    "So, let's try and read it in again. This time, 1) use `skip_header` to skip the header lines, and 2) specify it's a comma delimited file using `delimiter`. Note that we skip the top 5 lines and not just the top 3 because we also need to ignore the column names (5th line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdata = np.genfromtxt(file, skip_header=5, delimiter=',')\n",
    "print(tmpdata)\n",
    "\n",
    "type(tmpdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab4919",
   "metadata": {},
   "source": [
    "So, we just read our data into a NumPy ndarray, which is a type of NumPy n-dimensional structure used for storing data like a matrix. In our case we have a two dimensional data struture similar to a spreadsheet. Everything is together in a single large data structure at the moment, but we’ll see later in the lesson how to divide up our data and make interacting with it easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559a12e",
   "metadata": {},
   "source": [
    "### 1.3 Exploring a dataset\n",
    "\n",
    "Let’s now have a look at the data types in our ndarray. We can find this in the `dtype` attribute that is part of the ndarray data type, something that is known automatically for this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8573f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmpdata.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b102c90",
   "metadata": {},
   "source": [
    "Our data our floating point values with 64-bit precision. There are some exceptions, but 99% of all NumPy arrays will have the same data type.\n",
    "\n",
    "Now lets check how many dimensions there are using `ndim` and how many rows and columns we have using `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dimensions:', tmpdata.ndim)\n",
    "print('shape:', tmpdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e38dbe",
   "metadata": {},
   "source": [
    "We have 51 rows of data and 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f29e6",
   "metadata": {},
   "source": [
    "### 1.4 Indexing our array\n",
    "\n",
    "Like lists, arrays can be indexed and sliced using those index values. Let's look at our data again and focus on the data in third row and first column.\n",
    "Key to remember is python indexing starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f346578",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Uncomment below if you want to have a look at the entire array. \n",
    "##print(tmpdata)\n",
    "\n",
    "##The command in L. 6 just shows the number that is found in the third row, first column.\n",
    "tmpdata[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd054306",
   "metadata": {},
   "source": [
    "`tmpdata[2,0]` gives us the value of the data in the third row (which is row 2 in python because python indexing starts at 0), and first column. \n",
    "\n",
    "Similar to list or string slicing, we can also obtain ranges of rows and columns using `:`. To get the first 10 rows in the first column. So like, a [0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdata[:10, 0] #here, we get all the rows up to, but not including, index 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3055755",
   "metadata": {},
   "source": [
    "The column headers for this dataset were YEARMONTHDAY, TAVG, TMAX, and TMIN. Sometimes it's easier to break the data apart and put them back together. So, I'm going to extract all the values from a given column and make them each individual variables (date, average temp (tavg), maximum temp (tmax), and minimum temp (tmin))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2e096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = tmpdata[:,0]\n",
    "# print dates\n",
    "print(\"dates:\", date)\n",
    "\n",
    "tavg = tmpdata[:,1]\n",
    "tmax = tmpdata[:,2]\n",
    "tmin = tmpdata[:,3]\n",
    "\n",
    "# print min temps\n",
    "print(\"min temps:\", tmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d266a91",
   "metadata": {},
   "source": [
    "Remember those magic commands. We can see all the data types we have defined at this point using the `%whos` magic command. When we do this, we might realize that it is very foolish - even though this is a small file - to be storing these data that have no precision past a decimal as floating point, so let's at least convert the data column into the `int` datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4af02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%whos\n",
    "\n",
    "date = date.astype('int')\n",
    "\n",
    "print(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffab9fe",
   "metadata": {},
   "source": [
    "### 1.5 Basic data calculations\n",
    "\n",
    "Numpy arrays have a set of attributes and methods to make calculations using the data in the array. Useful methods include, `.mean()`, `.median()`, `.min()`, `.max()`, and `.std()`. \n",
    "\n",
    "Let's find the average temperature it's been in Richmond in 2025. (The historical average is around 37 deg F. This is the first time in about 40 years we've had a winter with close to average (1850-2010) temperatures - last winter 7 degrees warmer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a71bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tavg.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b063c9",
   "metadata": {},
   "source": [
    "QUICK NOTE: We can do the same calculation on the big dataset by summarizing across an axis. axis = 0 = sum vertical axis, downwards, over all the rows in a column, axis = 1 = summarizing across the horizontal axis, across-words, over all the columns in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(suppress=True) # only toggle this on if you hate scientific notation as much as Prof Spera (switch to False to return to scientific notation)\n",
    "print(np.mean(tmpdata, axis=0)) # this will print the average date, averge temp, min temp and max temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a979f",
   "metadata": {},
   "source": [
    "People love numpy because it is super easy to do calculations. Remember back in Lesson 1 where we had to figure out how to take one value in Farenheit and convert it to Celsius. Well, now that we have numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average RVA temp in F:\", tavg)\n",
    "\n",
    "tavg_C = (tavg - 32) / (9/5)\n",
    "\n",
    "print(\"average RVA temp in C:\", tavg_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d797ecd",
   "metadata": {},
   "source": [
    "### 1.6 Filtering data and using masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e8cbd",
   "metadata": {},
   "source": [
    "We can also filter data based on certain criterion. Let's say we wanted to know which days had average temps above 60 F/15 C in 2025, and then do the same but only for the month of January (the dataset currently includes both January and February). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800ddf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First lets see if there were any days in our whole dataset above 60. \n",
    "warmTemps = tavg_C[tavg_C > 15]\n",
    "print(warmTemps)\n",
    "\n",
    "# There was one day. Did it occure in Jan?\n",
    "warmTempsJan = tavg_C[(tavg_C > 15) & (date < 20250201)]\n",
    "print(warmTempsJan) \n",
    "print(\"There were\", len(warmTempsJan), \"days in January w average temps above 15 C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca16c2",
   "metadata": {},
   "source": [
    "Last year, there were 3 days > 60F in Jan.\n",
    "\n",
    "It's more likely that instead of filtering data, you'll want to mask it. So, what if we want to identify the dates with temperatures above 15C and keep only those dates in all of our other data columns. To do that, we'll use a mask array. \n",
    "\n",
    "A mask array is basically a boolean (True/False) array that can be used to take a subset of data from other data. So, instead of extracting warm temperatures directly, we'll first identify where those elements in `tavg_C` are greater than 15C (`True`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ff15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmTempsMask = tavg_C > 15\n",
    "print(warmTempsMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f9eb1",
   "metadata": {},
   "source": [
    "We can see there was one day in Feb above 60. Now we can use this mask on other columns of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmTempDates = date[warmTempsMask]\n",
    "print(warmTempDates) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7cefc8",
   "metadata": {},
   "source": [
    "### 1.7 Removing missing and bad data\n",
    "\n",
    "In some cases, a data file might contain missing values or values that cannot be read. These may be replaced by `nan` values when you look at your data. `nan` stands for “not a number”, and often we want to get rid of these things.\n",
    "\n",
    "Let’s consider a case where we have an array `badData` that is full of zeros, has the same size as `date` and the other arrays from our data file, and the first 5 rows have `nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dab08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some bad data in an array the length of our date matrix just as an example\n",
    "badData = np.zeros(len(date))\n",
    "badData[:5] = np.nan\n",
    "print(badData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189fe8",
   "metadata": {},
   "source": [
    "If we wanted to include values for the date column that only correspond to locations in `badData` where we do not have a nan value, we can use the `isfinite()` function in NumPy. `isfinite()` checks to see if a value is defined (i.e., is not `nan` or infinite (`inf`)). \n",
    "\n",
    "So, we'll make a mask to find where the data is **finite** and only pull the dates associated with the good data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee451993",
   "metadata": {},
   "outputs": [],
   "source": [
    "badDataMask = np.isfinite(badData)\n",
    "print(badDataMask)\n",
    "goodDates = date[badDataMask]\n",
    "print(goodDates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ac3b3",
   "metadata": {},
   "source": [
    "### 1.8 Re-creating and saving an array\n",
    "\n",
    "We've mostly worked with single columns that we spliced after bringing in our temperature data. We can create the 2d data structure by stacking these columns back together. Let's pull together our `date` and `tavg_C` columns in a new array called `tempdata_C`. We'll use the `vstack()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286b6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempdata_C = np.vstack((date,tavg_C))\n",
    "print(tempdata_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7260293",
   "metadata": {},
   "source": [
    "Something looks weird here. Let's invsetigate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9a2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tempdata_C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce52ff",
   "metadata": {},
   "source": [
    "It looks like there are two rows and 49 columns. The columns and rows need to be flipped. We can do this using `transpose()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata_C = np.transpose(tempdata_C)\n",
    "print(tempdata_C.shape)\n",
    "print(tempdata_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d87a7",
   "metadata": {},
   "source": [
    "Now that our data looks good, we can save it using `savetxt()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('rva_temps_C.csv', tempdata_C, delimiter=',') #check to see if it saved!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ac940",
   "metadata": {},
   "source": [
    "Note that instead of using the `vstack()` function, followed by the `transpose()` function, we could have stacked horizontally using the `hstack()` function to directly get the data set up as we wanted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22333a",
   "metadata": {},
   "source": [
    "## Knowledge Check 1\n",
    "Find the average minimum temperature and average maximum temperature during the first week of February. Then, determine how many days went below freezing and print out those dates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fe143",
   "metadata": {},
   "source": [
    "<a href=#home>Return to Top</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba844940",
   "metadata": {},
   "source": [
    "# 2. Matplotlib <a name='bookmark2' />\n",
    "\n",
    "Python has a **ton** of useful [libraries for plotting](https://rougier.github.io/python-visualization-landscape/landscape-colors.png). Matplotlib is probably the most widely used and it is [*polarizing*](https://www.reddit.com/r/Python/comments/p59091/anyone_else_despises_matplotlib/). The *cooler* [Seaborn](https://seaborn.pydata.org/) is built a top of Matplotlib. \n",
    "\n",
    "Matplotlib used to have a 'basemap' toolkit for making maps, but that's being depreciated for [Cartopy](https://scitools.org.uk/cartopy/docs/latest/) which we'll briefly touch on below.\n",
    "\n",
    "[Boken](https://docs.bokeh.org/en/latest/), [Plotly](https://plotly.com/python/), and [Dash](https://plotly.com/dash/) are fancy plotters.\n",
    "\n",
    "And, if you love ggplot2 (ALEX), python has it's own [ggplot](https://yhat.github.io/ggpy/). Here, we'll walk you through the standard matplotlib package, but great documentation exists for all of these plotting packages. \n",
    "\n",
    "## 2.1 Plotting basics\n",
    "There are a bunch of different types of plots:\n",
    "* [Bar chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)\n",
    "* [Histogram](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)\n",
    "* [Scatter plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html)\n",
    "* [Line chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html)\n",
    "* [Pie chart](https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_features.html)\n",
    "* [Violin chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.violinplot.html) # a better box plot\n",
    "* [Dendrogram](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)\n",
    " \n",
    "Most - if not all - of these plots have common elements. The figure hyperlinked [here](https://geo-python-site.readthedocs.io/en/2022.0/_images/basic-elements-of-plot.png) has a lot of the basic plot elements. \n",
    "\n",
    "Some common terms are:\n",
    "* *axis* - axes of graph (x, y, z if you're extra)\n",
    "* *title* - plot title\n",
    "* *label* - name of axis (xlabel or ylabel)\n",
    "* *legend* - plot legend\n",
    "* *tick label* - text/values represented on the axis\n",
    "* *symbol* - symbol for data points (on a scatter plot usually) that can presented w. different shapes and colors\n",
    "* *size* - size of a point on a scatter plot OR text sizes on a plot\n",
    "* *line style* - how the line should be drawn: solid, dashed, those stars\n",
    "* *line width* - width of line\n",
    "* *alpha* - transparency level of a filled element on a plot: 0 = fully transparent, 1 = fully opaque \n",
    "* *ticks* - tick marks\n",
    "* *annotation* - text added to a plot\n",
    "* *padding* - distance between an axis/tick label and axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893383cc",
   "metadata": {},
   "source": [
    "## 2.2 Loading and manipulating our data\n",
    "\n",
    "We need to import matplotlib, and we're going to use our dataset from earlier for some visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad9ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "filepath = \"/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/RVA_janfeb2025.csv\"\n",
    "data = np.genfromtxt(filepath, skip_header=5, delimiter=',')\n",
    "print(data)\n",
    "\n",
    "#I'm going to subset the data to just february\n",
    "data=data[31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling out each column like above\n",
    "date = data[:,0]\n",
    "tavg = data[:,1]\n",
    "tmax = data[:,2]\n",
    "tmin = data[:,3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0d4fc",
   "metadata": {},
   "source": [
    "## 2.3 Plotting\n",
    "\n",
    "Plots are automatically displayed in Jupyter notebooks, so you don't need `plt.show()`. But, if you're just working in Anaconda or from the terminal, you'll need to add that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = date\n",
    "y = tavg\n",
    "plt.plot(x, y)\n",
    "\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece533f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let's make our graph better\n",
    "plt.plot(x, y, 'ro--')\n",
    "plt.title('RVA temperatures Feb 2025')\n",
    "plt.xlabel('Day of Month')\n",
    "plt.ylabel('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1adc4e",
   "metadata": {},
   "source": [
    "Now we see our temperature data as a red dashed line with circles showing the data points. This comes from the additional `ro--` used with `plt.plot()`. In this case, `r` tells the `plt.plot()` function to use red [color](https://matplotlib.org/stable/gallery/color/named_colors.html), `o` tells it to show circles at the [points](https://matplotlib.org/1.4.1/api/markers_api.html), and `--` says to use a dashed line. You can use `help(plt.plot)` to find out more about formatting plots, OR, click on [this link](https://matplotlib.org/1.4.1/api/axes_api.html#matplotlib.axes.Axes.plot) to see all of the great documentation.\n",
    "\n",
    "### Embiggening\n",
    "\n",
    "While the plot sizes we’re working with are OK, you can display them to be any size you want in Jupyter notebooks. To set the default plot size to be larger, simply run the Python code in a new cell below.\n",
    "\n",
    "```python\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "```\n",
    "That would set the default plot size to be 12 inches wide by 6 inches tall. You can run that and then rerun any of the plotting cells and see what happens.\n",
    "\n",
    "### Text labels\n",
    "If you want to add text to plots, you can do that using `plt.text()`.\n",
    "\n",
    "```python\n",
    "plt.text(20240126, 72, 'Too hot')\n",
    "```\n",
    "\n",
    "This will display the aforementioned text at the location `x = 20140126` (i.e., Jan 26, 2024), at `y = 72`, on the plot. We’ll see how to do this in a real example in just a second. With our approach to plotting thus far (we'll see another approach in Section 2.5), the commands related to an individual plot should all be in the same Python cell.\n",
    "\n",
    "### Changing the axis ranges\n",
    "\n",
    "We can change the plot axes using `plt.axis()`\n",
    "```python\n",
    "plt.axis([20240101, 20240131, 20, 80])\n",
    "```\n",
    "\n",
    "The format for `plt.axis()` is `[xmin, xmax, ymin, ymax]` in square brackets (because it's a list!). Let's put this together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21327325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'ro--')\n",
    "plt.title('RVA temperatures Feb 2025')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°F)')\n",
    "plt.text(20250204, 62, 'Too hot')\n",
    "plt.axis([20250201, 20250218, 30, 65])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9b8ea",
   "metadata": {},
   "source": [
    "## 2.4 Customizing Plots\n",
    "\n",
    "We don't need to use numpy data or pandas data or even text data to create plots. We'll work with two lists to learn some of the myriad ways we can customize our plots.\n",
    "\n",
    "We're going to look at average monthly precipitation in Richmond between 1991 and 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9af5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists using data found here: \n",
    "# https://www.weather.gov/media/akq/climateRECORDS/RIC_Climate_Records.pdf\n",
    "\n",
    "rva_pcp = [3.21, 2.61, 4.0, 3.18, 4.0, 4.64, 4.37, 4.9, 4.61, 3.39, 3.06, 3.51]\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "plt.plot(months, rva_pcp)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddaac7f",
   "metadata": {},
   "source": [
    "Note that the output displays the object type as well as the unique identifier (or the memory location) for the figure.\n",
    "\n",
    "You can hide this information from the output by adding plt.show() - or commenting it out above - as the last line you call in your plot code.\n",
    "\n",
    "#### Let's get customizing. \n",
    "By default, `plt.plot()` creates a line plot. This is not an ideal situation for plotting precipitation. \n",
    "\n",
    "What about a scatter plot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb3188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(months,rva_pcp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e470dd",
   "metadata": {},
   "source": [
    "Okay but this is useless for precipitation too. Let's make a bar chart instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0dace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, rva_pcp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e928b87",
   "metadata": {},
   "source": [
    "Great, let's add a title and axes like we learned to above but with a fancy line break designated by `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, rva_pcp)\n",
    "\n",
    "plt.title('Average Monthly Precipitation in RVA\\n1991-2020')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation\\n(inches)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb1b4d",
   "metadata": {},
   "source": [
    "Now let's adjust the transparency using `alpha` and color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, \n",
    "        rva_pcp, \n",
    "        color = 'dodgerblue', \n",
    "        edgecolor = 'darkslateblue', \n",
    "        alpha = 0.25)\n",
    "\n",
    "plt.title('Average Monthly Precipitation in RVA\\n1991-2020')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation\\n(inches)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1602903",
   "metadata": {},
   "source": [
    "#### Saving your plots\n",
    "\n",
    "Saving plots created using Matplotlib can be done several ways. The recommendation for use outside of Jupyter notebooks is to use the `plt.savefig()` function. When using `plt.savefig()`, you simply give a list of commands to generate a plot and list `plt.savefig()` with some parameters as the last command. The file name is required, and the image format will be determined based on the listed file extension.\n",
    "\n",
    "Matplotlib plots can be saved in a number of useful file formats, including PNG, PDF, and EPS. PNG is a nice format for raster images, and EPS is probably easiest to use for vector graphics. Let’s check out an example and save our lovely bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19aa040",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(months, \n",
    "        rva_pcp, \n",
    "        color = 'dodgerblue', \n",
    "        edgecolor = 'darkslateblue', \n",
    "        alpha = 0.25)\n",
    "\n",
    "plt.title('Average Monthly Precipitation in RVA\\n1991-2020')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Precipitation\\n(inches)')\n",
    "plt.savefig('rva_month_pcp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cad6df",
   "metadata": {},
   "source": [
    "Check your folder to see if a PNG file was created - click on it to take a look!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bee94",
   "metadata": {},
   "source": [
    "### Knowledge Check 2\n",
    "Using *RVA_PRECIP_janfeb2025.csv* data found that same Lesson4_2025 folder, plot either total daily precipitation, snowfall, or snowdepth in **January 2025** as a bar graph. Try out some nice formatting to make your graph look nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3961ad",
   "metadata": {},
   "source": [
    "<a href=#home>Return to Top</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9491c",
   "metadata": {},
   "source": [
    "## 2.5 Subplots\n",
    "\n",
    "If we wanted to level up, we could use subplots. Earlier we said that everything needed to be in the same Jupyter notebook cell block if we wanted it to all plot together. But, that wasn't giving matplotlib enough credit. \n",
    "\n",
    "Matplotlib uses an object oriented approach to plotting. This means that plots can be built step-by-step by adding new elements to the plot.\n",
    "\n",
    "There are two primary objects associated with a matplotlib plot:\n",
    "* `figure` object: the overall figure space that can contain one or more plots.\n",
    "* `axis` objects: the individual plots that are rendered within the figure.\n",
    "\n",
    "You can think of the figure object as your plot canvas. You can think about the axis object as an individual plot. See [this image](https://www.earthdatascience.org/images/earth-analytics/plot-data/fig-1-plot.png).\n",
    "\n",
    "A figure can hold one or more axis objects. This structure allows you to create figures with one or more plots on them.\n",
    "\n",
    "To create a plot using matplotlib’s object oriented approach, you first create the figure (which you can call `fig`) and at least one axis (which you can call `ax`) using the `subplots()` function from the pyplot module:\n",
    "\n",
    "`fig, ax = plt.subplots()`\n",
    "\n",
    "Notice that the `fig` and `ax` are created at the same time by setting them equal to the output of the `pyplot.subplots()` function. As no other arguments have been provided, the result is a figure with one plot that is empty but ready for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b094324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and one plot (axis object) \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf7beb",
   "metadata": {},
   "source": [
    "This format comes in handy, particularly, when working with [multiplot figures](https://www.earthdatascience.org/images/earth-analytics/plot-data/fig-4-plots.png).\n",
    "\n",
    "Note: In the example above, `fig` and `ax` are variable names for the figure and axis objects. You can call these items whatever you want. For example, you might see f, ax or fig, axis1 used.\n",
    "\n",
    "When adding more than one axis object, it is good practice to give them distinct names (such as `ax1` and `ax2`), so you can easily work with each `axis` individually.\n",
    "\n",
    "You will need to provide new arguments to `plt.subplots` for the layout of the figure: number of rows and columns:\n",
    "\n",
    "`plt.subplots(1, 2)`\n",
    "\n",
    "In this example, 1, 2 indicates that you want the plot layout to be 1 row across 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8631754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure with two plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dba7ec",
   "metadata": {},
   "source": [
    "Conversely, (2, 1) indicates that you want the plot layout to be 2 rows across one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fa3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure with two plots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf0a28",
   "metadata": {},
   "source": [
    "A key benefit of the matplotlib object oriented approach is that each axis is its own object and can be customized independently of the other plots in the figure.\n",
    "\n",
    "Let's make a subplot with some seasonal minimum temperature data from Acadia National Park from 1950-2021 that Prof Spera has worked with.\n",
    "The data files are in the `/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/` directory.\n",
    "* djf_tmin_acadia.csv\n",
    "* mam_tmin_acadia.csv\n",
    "* jja_tmin_acadia.csv\n",
    "* son_tmin_acadia.csv\n",
    "\n",
    "Check out the data before you load it. Note that each data file indicates the average minimum temperature over 1950-2021 for a set if three months. 'djf' stands for 'December, January, February', and thus indicates the average minimum temperatures in winter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef74f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "djf_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/djf_tmin_acadia.csv\" #winter\n",
    "mam_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/mam_tmin_acadia.csv\" #spring\n",
    "jja_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/jja_tmin_acadia.csv\" #summer\n",
    "son_file = \"/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/son_tmin_acadia.csv\" #autumn\n",
    "\n",
    "# get time series data\n",
    "djfTS = np.genfromtxt(djf_file, skip_header=1, delimiter=',')\n",
    "mamTS = np.genfromtxt(mam_file, skip_header=2, delimiter=',') \n",
    "jjaTS = np.genfromtxt(jja_file, skip_header=2, delimiter=',')\n",
    "sonTS = np.genfromtxt(son_file, skip_header=2, delimiter=',')\n",
    "\n",
    "# turn the dates into integers\n",
    "years = (djfTS[:,0]).astype(int)\n",
    "\n",
    "# pull minimum temperature info from each dataset\n",
    "djf_tmin = djfTS[:,1]\n",
    "mam_tmin = mamTS[:,1]\n",
    "jja_tmin = jjaTS[:,1]\n",
    "son_tmin = sonTS[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357d537",
   "metadata": {},
   "source": [
    "Lets plot the seasons separately, quickly, just to get a feel for what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(djf_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4d42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mam_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(jja_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99aafb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(son_tmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb67d4",
   "metadata": {},
   "source": [
    "Okayyy, let's make these subplots.  First, we can create a 2x2 panel for our visualization using Matplotlib’s `subplots()` function where we specify how many rows and columns we want to have in our figure. We can also specify the size of our figure with `figsize` parameter as we have seen earlier with pandas. Figsize takes the width and height values (in inches!) as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a013162",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd84d2",
   "metadata": {},
   "source": [
    "You can see that as a result we have now a list containing two nested lists where the first one contains the axis for columns 1 and 2 on row 1, and the second list contains the axis for columns 1 and 2 for row 2.\n",
    "\n",
    "We can split these axes into their own variables so it is easier to work with them.\n",
    "\n",
    "```\n",
    "ax11 = axes[0][0]\n",
    "ax12 = axes[0][1]\n",
    "ax21 = axes[1][0]\n",
    "ax22 = axes[1][1]\n",
    "```\n",
    "\n",
    "After running that, we have four variables for our plot axes that we can use for the different panels in our figure. We will use them to plot the seasonal data. Let’s begin by plotting the seasons, and use different colors for the lines and specify the y-axis range to be the same for all subplots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba06c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax11 = axes[0][0]\n",
    "ax12 = axes[0][1]\n",
    "ax21 = axes[1][0]\n",
    "ax22 = axes[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034938b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot line width\n",
    "line_width = 1\n",
    "\n",
    "# Plot data\n",
    "ax11.plot(years, djf_tmin, c=\"slategrey\", lw=line_width)#, set_ylim=([min_temp, max_temp]))\n",
    "ax12.plot(years, mam_tmin,  c=\"orchid\", lw=line_width)#, ylim=[min_temp, max_temp])\n",
    "ax21.plot(years, jja_tmin, c=\"olivedrab\", lw=line_width)#, ylim=[min_temp, max_temp])\n",
    "ax22.plot(years, son_tmin, c=\"orangered\", lw=line_width)#, ylim=[min_temp, max_temp])\n",
    "\n",
    "# Set figure title\n",
    "fig.suptitle(\"Average annual season temperature at \\nAcadia National Park, Maine\")\n",
    "\n",
    "# Rotate the x-axis labels so they don't overlap\n",
    "plt.setp(ax11.xaxis.get_majorticklabels(), rotation=20)\n",
    "plt.setp(ax12.xaxis.get_majorticklabels(), rotation=20)\n",
    "plt.setp(ax21.xaxis.get_majorticklabels(), rotation=20)\n",
    "plt.setp(ax22.xaxis.get_majorticklabels(), rotation=20)\n",
    "\n",
    "# Axis labels\n",
    "ax11.set_ylabel(\"Temperature [°C]\")\n",
    "ax21.set_ylabel(\"Temperature [°C]\")\n",
    "\n",
    "# Season label text\n",
    "# The first to numbers are where on the graph you want to put the text\n",
    "ax11.text(2010, -8, \"Winter\")\n",
    "ax12.text(2010, 0.5, \"Spring\")\n",
    "ax21.text(2010, 12.5, \"Summer\")\n",
    "ax22.text(2010, 6.5, \"Autumn\")\n",
    "# Display the figure\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e42372",
   "metadata": {},
   "source": [
    "FUN!\n",
    "\n",
    "If you run stats on these data, you'd see a statisically significant increase in minimum temperatures in fall, winter, and summer in Acadia. Nothing is happening in the spring!\n",
    "\n",
    "Fall nights are about 1.2°C (2.1°F) warmer on average now than 1950.\n",
    "Winter nights are about 1.4°C (2.5°F) warmer on average now than in 1950.\n",
    "And summer nights are about 1.6°C (2.9°F) warmer on average now than in 1950.\n",
    "\n",
    "### Knowledge Check 3\n",
    "In the temperature data from the numpy section, you had three columns of temperature data - min, max, and average. Make three plots in one figure that depicts each of these. Remember to make your graph look nice using good formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48ccdf",
   "metadata": {},
   "source": [
    "<a href=#home>Return to Top</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91992c",
   "metadata": {},
   "source": [
    "# 3. Cartopy <a name='bookmark3' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9bc0e",
   "metadata": {},
   "source": [
    "Cartopy is one of many packages that focuses on geospatial data. This means it can be used for plotting data on a map, but it can also be used for plotting geographical images such as sections of a Google map. \n",
    "\n",
    "Like Matplotlib, Cartopy has several different modules. We will be working with two important modules in this tutorial: `crs` and `feature`. \n",
    "\n",
    "`crs` is the basic map-making module that creates the coordinates that we want. \n",
    "`feature` allows us to add coastlines, borders, oceans, and other important distinctions to our maps.\n",
    "\n",
    "More info about Cartopy can be found [here](https://scitools.org.uk/cartopy/docs/latest).\n",
    "\n",
    "**Important: Before we move on, we have to change conda environments because cartopy is a tricky package. At the top of the page, click 'Kernel'>'Change kernel'>'qgis.' If people are really interested in why we have to do this, we can chat about conda environments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from cartopy import crs, feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd66fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we'll be using ozone data\n",
    "data = pd.read_csv('/scratch/myang_shared/lab/PythonBootcamp/Sp25/resources/Lesson4_2025/july20_ozone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8cda91",
   "metadata": {},
   "source": [
    "Examine the data. What are the column names? What's the shape and size? Etc.\n",
    "\n",
    "Now let's pull some stuff together from a bunch of previous lessons to manipulate the data and make sure we're doing what we want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba0c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's deal with the dates\n",
    "dates = pd.to_datetime(data.loc[:, 'Date Local'])\n",
    "\n",
    "# add the dattimes back to the dataframe\n",
    "data['datetimes'] = dates\n",
    "\n",
    "# and now just double check that we did it right\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1d80c",
   "metadata": {},
   "source": [
    "Let's look at some trends over time using the super handy `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ea7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['Date Local'][0]))\n",
    "print(type(data['datetimes'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad02f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_o3 = data.filter(items=['Ozone (ppm)', 'datetimes']).groupby(data['datetimes'].dt.day).mean()\n",
    "daily_avg_o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plot\n",
    "y=daily_avg_o3['Ozone (ppm)']\n",
    "x=daily_avg_o3.index\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Day of Month')\n",
    "plt.ylabel('Ozone (ppm)')\n",
    "plt.title('July Daily Average Ozone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf976e5",
   "metadata": {},
   "source": [
    "This plot is telling us that the average ozone concentration across the entire United States fluctuates by less than 10 ppb during the month of July. But what is happening at specific locations? Can we zoom in to an area to better understand how air quality is changing there?\n",
    "\n",
    "Let's look specifically at Massachusetts. (Virginia was boring.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9190f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = data.loc[data['State Name']=='Massachusetts']\n",
    "ma\n",
    "\n",
    "ma_avg_o3 = ma.filter(items=['Ozone (ppm)', 'datetimes']).groupby(ma['datetimes'].dt.day).mean()\n",
    "\n",
    "y_ma = ma_avg_o3['Ozone (ppm)']\n",
    "x_ma = ma_avg_o3.index\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(x_ma,y_ma)\n",
    "plt.xlabel('Day of Month')\n",
    "plt.ylabel('Ozone (ppm)')\n",
    "plt.title('July Daily Average Ozone in Massachusetts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720269f0",
   "metadata": {},
   "source": [
    "Okay, it seems like there is something else going on in Massachusetts. We can assume ozone, then, varies in time and space. Let's make a map to see which areas in MA have high concentrations of ozone and which have low concentrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d88f12",
   "metadata": {},
   "source": [
    "## 3.1. Making a map\n",
    "\n",
    "We generally need to follow the same steps to make a map:\n",
    "* a. Identify the coordinates of your region of interest (ROI)\n",
    "* b. Make a grid on your coordinates of interest\n",
    "* c. Select a map project\n",
    "* d. Create a pyplot figure using your grid and map project\n",
    "* e. Add the relevant features to your figure\n",
    "* f. Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b383662",
   "metadata": {},
   "source": [
    "### 3.1.a. Identify the coordinates of your ROI\n",
    "\n",
    "Sometimes, your data will have a pre-made grid of the latitude and longitude coordinates for you. This makes it really easy. In other cases, you might need to decide on the coordinates yourself. Our data does have latitude and longitude coordinates, but it does not tell us the size of the grid we want. We can use our latitude and longitude data to make an appropriately sized grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41626ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latmin = ma['Latitude'].min()\n",
    "latmax = ma['Latitude'].max()\n",
    "lonmin = ma['Longitude'].min()\n",
    "lonmax = ma['Longitude'].max()\n",
    "print('Lat Range: %.4f - %.4f' % (latmin,latmax))\n",
    "print('Lon Range: %.4f - %.4f' % (lonmin,lonmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a6ad5",
   "metadata": {},
   "source": [
    "Now that we know our max/min - we can make a box around our data. I like adding a little bit of a spatial buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae69702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffered lats and lons\n",
    "latmin = 41\n",
    "latmax = 43\n",
    "lonmin= -74\n",
    "lonmax = -69.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7e092",
   "metadata": {},
   "source": [
    "### 3.1.b. Make a grid\n",
    "\n",
    "This step will vary depending on the type of data you are plotting. We will be making a simple dot map, so we basically need to set a max and min range for our map's box size. If we were using gridded data that covered the whole area, like satellite data or a model output, we would need to make a meshgrid that had a lat and lon coordinate pair for each grid cell. Prof Spera can write up something on this if people are interested.\n",
    "\n",
    "`extent` below indicates the boundaries of our map's box size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [lonmin, lonmax, latmin, latmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffbbb5",
   "metadata": {},
   "source": [
    "### 3.1.c. Select a map projection.\n",
    "We also need to decide on a map projection. A map projection tells you how the map will be displayed. If you've taken Geog/Envs 260, you'll hopefully have heard all about projections. There's more info [here](https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html), but the basic idea is that a map represents a sphere (our globe), and so visualizing it in a 2d space can look really different depending on the projection used to put the map into 2d space. Here, we'll use the plate carree projection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection\n",
    "proj = crs.PlateCarree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cfd7e",
   "metadata": {},
   "source": [
    "### 3.1.d. Create a Figure\n",
    "\n",
    "Let's try and put everything together in a pyplot figure to set up our map background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "# ax.set_extent([lonmin,lonmax,latmin,latmax],crs.PlateCarree())\n",
    "ax.set_extent(extent)\n",
    "# # add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace7206",
   "metadata": {},
   "source": [
    "Note that cartopy is built on top of matplotlib tools! Thus, knowing matplotlib is important for a lot of visualization techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defabec",
   "metadata": {},
   "source": [
    "### 3.1.e. Add relevant figures. \n",
    "Let's make sure this is in the right place by adding details like rivers, state borders, etc.\n",
    "\n",
    "Note: If you are getting DownloadWarnings but the figure does appear, then don't worry. If you rerun the cell, you will see the DownloadWarning has disappeared. If you add new features, you will get a new warning, but it'll go away the next time you use that feature. When Cartopy was initially installed, it didn't download all the different map features with it. So it has to download them the first time you want to use those features in a plot - this might make the job run a bit longer than normal - it should still finish in ~1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "# IF YOU GET DOWNLOAD WARNINGS, JUST WAIT THEM OUT. THINGS WILL PROCESS. \n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.RIVERS)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8896c50",
   "metadata": {},
   "source": [
    "Note that the `.add_feature()` method is from cartopy and will pull out built-in data on state boundaries and river layouts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6da898",
   "metadata": {},
   "source": [
    "### 3.1.f. Plot the data\n",
    "\n",
    "The daily ozone data has lat and lon coordinates. But we have data for every day in the month of July, which is too much to plot all at once. Instead, let's pick just one day and plot that data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234780aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get data from July 1\n",
    "july_1=ma[ma['datetimes']=='2020-07-01']\n",
    "\n",
    "july_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lat, lon and y-data\n",
    "lats = july_1['Latitude']\n",
    "lons = july_1['Longitude']\n",
    "o3 = july_1['Ozone (ppm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fedf79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "\n",
    "# ax.add_feature(feature.RIVERS)\n",
    "\n",
    "# plot the data -- note, we use plt.scatter to add data on top of the map!\n",
    "plt.scatter(lons,lats,s=50,c=o3)\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5, pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b18730",
   "metadata": {},
   "source": [
    "Wow, so it seems like southeastern Massachusetts where Prof Spera is from has higher concentrations of ozone than the rest of the state. But, if you remember from the line graph above, ozone was highest across the state on July 19. Let's see if we have the same spatial pattern then as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60103ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select monitor data from July 31st\n",
    "july19 = ma.loc[ma['datetimes'] == '2020-07-19']\n",
    "\n",
    "# get the lat, lon, and y-data\n",
    "lats = july19['Latitude']\n",
    "lons = july19['Longitude']\n",
    "o3 = july19['Ozone (ppm)']\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "# ax.add_feature(feature.RIVERS)\n",
    "# plot the data -- note, we use plt.scatter to add data on top of the map!\n",
    "plt.scatter(lons,lats,s=50,c=o3)\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5, pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6b7b1",
   "metadata": {},
   "source": [
    "Totally different pattern! Amtospheric chemistry changes in space & time. \n",
    "\n",
    "Note here that the heatmap key is covering a bit of the y-axis label on the right. Mess around with the `plt.colorbar` options - can you make it so the heatmap key doesn't cover parts of the graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee877f",
   "metadata": {},
   "source": [
    "### Knowledge Check 4\n",
    "Map a state that isn't Massachusetts using the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09ded9",
   "metadata": {},
   "source": [
    "<a href=#home>Return to Top</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6932945",
   "metadata": {},
   "source": [
    "## 3.2. A projection deep dive (skip this section if you're not interested)\n",
    "To evaluate the importance of projections, we really need to look on a larger scale than the state level. Since our ozone data is for the entire US, let's look at the total area covered by the data.\n",
    "[Projections](https://www.leventhalmap.org/digital-exhibitions/bending-lines/interactives/projection-face/) are essentially how we get a 3-d surface (the surface of the earth, which is a sphere), to a 2-d surface (a map). If you haven't taken Geog 260, see this [figure](https://media.licdn.com/dms/image/C4D12AQGszV4q-00Lew/article-inline_image-shrink_1500_2232/0/1634289520658?e=1712793600&v=beta&t=II_5VLlRGOnrkkU_dZwp6VOYR3q3gDdPwEUSNCPNBkQ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the min and max coordinates of monitors in our dataset?\n",
    "latmin = data['Latitude'].min()\n",
    "latmax = data['Latitude'].max()\n",
    "lonmin = data['Longitude'].min()\n",
    "lonmax = data['Longitude'].max()\n",
    "print('Lat Range: %.4f - %.4f' % (latmin,latmax))\n",
    "print('Lon Range: %.4f - %.4f' % (lonmin,lonmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325fa8e",
   "metadata": {},
   "source": [
    "Let's go through our map-making steps but for the whole US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the coordinates\n",
    "# buffered lat/lon values\n",
    "latmin = 15\n",
    "latmax = 65\n",
    "lonmin = -60\n",
    "lonmax = -150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1861fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Make the grid\n",
    "# set the extents of our box\n",
    "extent = [lonmin,lonmax,latmin,latmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e332239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Select the map projection\n",
    "# first, we'll stick with PlateCarree\n",
    "proj = crs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a figure\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42aed0",
   "metadata": {},
   "source": [
    "Okay, it appears we have states but not countries. Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7cc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7548bd0",
   "metadata": {},
   "source": [
    "Does the US seem to be the right shape? Or do things look a bit flattened? That's what happens with PlateCarree, it flattens out the map. Let's try some other projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a800a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albers Equal Area projection\n",
    "proj = crs.AlbersEqualArea()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562cc73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d80a1",
   "metadata": {},
   "source": [
    "The Albers Equal Area projection is a conical projection, meaning it pretends the globe is actually a cone and uses a conical projection. Not great either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bceb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lambert Conformal. This projection is useful if you ever use CMAQ or WRF data\n",
    "proj = crs.LambertConformal()\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966716f",
   "metadata": {},
   "source": [
    "We're getting better. At least the US is nearly centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a9561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Robinson projection\n",
    "proj = crs.Robinson()\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b7c02",
   "metadata": {},
   "source": [
    "This projection is good if you're mapping most of the world. You can find all of cartopy's projections [here](https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html). \n",
    "\n",
    "We've examined a few projections. Let's see how this can affect the data. Let's stick with the Robinson projection just for kicks and pick just one random day to focus on, and plot all monitor locations just to prove another point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea54c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's map July 4th, 2020\n",
    "sel_date = data[data['datetimes'] == '2020-07-04']\n",
    "\n",
    "# get the lat, lon, and y-data\n",
    "lats = sel_date['Latitude']\n",
    "lons = sel_date['Longitude']\n",
    "o3 = sel_date['Ozone (ppm)']\n",
    "\n",
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "# add data\n",
    "plt.scatter(lons,lats,s=10,c=o3)\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fa5ea",
   "metadata": {},
   "source": [
    "Wait! What happened? Where is the data? The lats, lons, and ozone variables definitely have values, so that isn't the problem. Why didn't any dots show up on the map?\n",
    "\n",
    "The answer is in the projection. We changed the map projection from Plate Carree to Robinson. But, we left the data in Plate Carree (flat) projection. In order to map our flat data onto a not-flat map, we need to transform it. This data + map being in the same projection gets a lot of people stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27c10c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a pyplot figure\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "# create a new axes instance with the map information\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "ax.set_extent(extent)\n",
    "# add gridlines\n",
    "gl = ax.gridlines(crs.PlateCarree(),draw_labels=True,linewidth=1,color='gray',alpha=0.5,linestyle='--')\n",
    "# add features\n",
    "ax.add_feature(feature.STATES)\n",
    "ax.add_feature(feature.COASTLINE)\n",
    "# add data\n",
    "plt.scatter(lons,lats,s=10,c=o3,transform=crs.PlateCarree()) # added transform here\n",
    "plt.colorbar(label='Ozone (ppm)',shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f515789",
   "metadata": {},
   "source": [
    "### Knowledge Check 5\n",
    "\n",
    "Pick a different projection and plot the average July ozone across just the contiguous US (no Alaska, Hawaii, or Puerto Rico). Notice any interesting spatial patterns across the US?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860df1a",
   "metadata": {},
   "source": [
    "<a href=#home>Return to Top</a> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qgis]",
   "language": "python",
   "name": "conda-env-qgis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
