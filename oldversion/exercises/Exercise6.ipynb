{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.1: Exception handling\n",
    "\n",
    "If you don't know them already, there are two functions to get rid of elements in a set: `remove()` and `discard()`.\n",
    "\n",
    "A. Now that we've learned more about exception handling, explain what is happening in the script below when you run it.\n",
    "\n",
    "B. Create a script that contains a list of at least five to-do tasks and celebrates each time you finish a task on your to-do list. Each time a task is done, it must be removed from the list and you must make a sentence indicating that the task being done is currently in progress. Then, if you call the task a second time, you will congratulate yourself on having completed the task. Try to do this using **try** and **except** statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_letters = ['a', 'a', 'b', 'c','c','c','d','e']\n",
    "print ('ORIGINAL')\n",
    "set_of_letters = set(list_of_letters)\n",
    "print (set_of_letters)\n",
    " \n",
    "print ('DISCARD')\n",
    "set_of_letters.discard('q')\n",
    "print (set_of_letters)\n",
    " \n",
    "print ('REMOVE')\n",
    "set_of_letters.remove('q')\n",
    "print (set_of_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 6.2: Improving the FASTA parser in the `sequence_tools.py` module (from Exercise 5.5) --\n",
    "Let's improve the FASTA parser! Make it handle:\n",
    "1. non-existent filenames. Return a print statement indicating the error.\n",
    "2. files that do not conform to the FASTA format (i.e. >gene for IDs, and strings of A,T,G, or C for sequence). Return a print statement indicating the error.\n",
    "3. sequences that are in both cases. Make sure the program can take in upper and lower cases without producing an error.\n",
    "\n",
    "Write a short script running the FASTA parser showing it can handle the above three situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 6.3: Filetypes __\n",
    "The `cerevisiae_genome.fasta` file in `resources/` is very large, such that we might prefer to save space on the computer by zipping the file. Look up the **gzip** Linux command and use it to zip the fasta file. \n",
    "\n",
    "However, now your file cannot be read by your fasta parser. Create a new function called `open_file_by_mimetype` that identifies the filetype and returns an open filehandle without error. This will require use of the **mimetypes** module (look it up, particularly the function `mimetypes.guess_type`) and the **gzip** module (look it up, particularly the `gzip.open` function). Modify your fasta parser accordingly so it can deal with more file types. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.4: All code is bug-free until your first user. --\n",
    "You have another coworker who made an AMAZING secondary structure analysis script. She used it on the protein 3GV2, inputting [the pdb file for 3GV2](http://www.rcsb.org/pdb/explore/explore.do?structureId=3GV2). She asks if you will analyze her protein, [interleukin-19](http://www.rcsb.org/pdb/explore/explore.do?structureId=1N1F), as well. (HINT: use PDB code 1N1F). Crud! This protein breaks your code. Why? Rewrite your code to work on both interleukin-19 and on the original 3GV2 HIV capsid protein.\n",
    "\n",
    "The script she shared is below. I recommend also downloading the pdb file for 3GV2, to see what a working final output should look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    " \n",
    "full_seq = []\n",
    "helix_aa = []\n",
    "sheet_aa = []\n",
    "atoms = []\n",
    "pd=\"/Users/myang/YangLab/PythonBootcamp/resources/\"\n",
    "f1 = open(pd+'1N1F.pdb' ,'r')\n",
    "for next in f1:\n",
    "    tmp = next.strip().split()\n",
    "    if tmp[0] == 'SEQRES':\n",
    "        if tmp[2] == 'A':\n",
    "            full_seq.extend(tmp[4:])\n",
    "    elif tmp[0] == 'HELIX':\n",
    "        try:\n",
    "            int(tmp[5])\n",
    "        except:\n",
    "            tmp[5] = tmp[5][:-1]\n",
    "        helix_aa.append(tmp[:9])\n",
    "    elif tmp[0] == 'SHEET':\n",
    "        sheet_aa.append(tmp[:10])\n",
    "    elif tmp[0] == 'ATOM':\n",
    "        if len(tmp) < 12:\n",
    "            begin = tmp[0:2]\n",
    "            end = tmp[3:]\n",
    "            middle = [tmp[2][:3], tmp[2][4:]]\n",
    "            tmp = begin + middle + end\n",
    "        try:\n",
    "            int(tmp[5])\n",
    "        except:\n",
    "            continue\n",
    "        atoms.append(tmp)\n",
    " \n",
    "######################\n",
    " \n",
    "num_helix_res = 0.0\n",
    "print (f\"There are {full_seq} residues in the sequence\")\n",
    " \n",
    "# Set up a listing of features by residue, then fill it in as we go along\n",
    "feature = ['Other']*(10000)\n",
    " \n",
    "for aa in helix_aa:\n",
    "    # We add 1 because there are b-a+1 residues between a and b, inclusive\n",
    "    num_helix_res += float(aa[8]) - float(aa[5]) + 1\n",
    "    for i in range(int(aa[5]), int(aa[8])+1):\n",
    "        feature[i] = 'Helix'\n",
    " \n",
    "num_sheet_res = 0.0\n",
    "for sheet in sheet_aa:\n",
    "    num_sheet_res += float(sheet[9]) - float(sheet[6]) + 1\n",
    "    for i in range(int(sheet[6]), int(sheet[9])+1):\n",
    "        feature[i] = 'Sheet'\n",
    " \n",
    " \n",
    " # atom[4] == chain id\n",
    " # atom[5] == residue #\n",
    " # atom[10] == b-factor\n",
    " \n",
    " \n",
    "helix_bfactors = {}\n",
    "sheet_bfactors = {}\n",
    "other_bfactors = {}\n",
    " \n",
    "for atom in atoms:\n",
    "    Chain = atom[4]\n",
    "    BFactor = float(atom[10])\n",
    "    ResidueNum = int(atom[5])\n",
    " \n",
    "    if feature[ResidueNum] == 'Helix':\n",
    "        if Chain not in helix_bfactors:\n",
    "            helix_bfactors[Chain] = []\n",
    "        helix_bfactors[Chain].append(BFactor)\n",
    "    elif feature[ResidueNum] == 'Sheet':\n",
    "        if Chain not in sheet_bfactors:\n",
    "            sheet_bfactors[Chain] = []\n",
    "        sheet_bfactors[Chain].append(BFactor)\n",
    "    else:\n",
    "        if Chain not in sheet_bfactors:\n",
    "            other_bfactors[Chain] = []\n",
    "        other_bfactors[Chain].append(BFactor)\n",
    "print (len(list(set(full_seq))))\n",
    "for chain in helix_bfactors:\n",
    "    # I could have used any of the different bfactor listings\n",
    "    avg_helix = sum(helix_bfactors[chain])/len(helix_bfactors[chain])\n",
    "    avg_sheet = sum(sheet_bfactors[chain])/len(sheet_bfactors[chain])\n",
    "    avg_other = sum(other_bfactors[chain])/len(other_bfactors[chain])\n",
    "    print (f'{chain}\\t{avg_helix:.5f}\\t{avg_sheet:.5f}\\t{avg_other:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.5: GENO2FASTA - CHALLENGE --\n",
    "\n",
    "Take the \"51.2.2M\" data from the resources/ file. Can you write a script where if you specify an individual, the script will use the geno/ind/snp files to turn the data into fasta format? Here are some things to keep in mind:\n",
    "1. Separate each fasta sequence in your file by chromosome. \n",
    "2. Make sure to keep all information you have for the individual in the header line (\">\") of the fasta - use \"|\" to separate different bits of information (including chromosome information). \n",
    "3. The two alleles in the \"snp\" file are what the 0/1/2 refer to. A zero indicates none of the first allele is found. A one indicates one of the first allele is found, and a two indicates both alleles are the first allele. If you have a '1', randomly choose one of the two alleles to keep in the fasta - look into the [**random** module](https://docs.python.org/3.8/library/random.html). You are essentially treating diploid individuals as haploid calls. \n",
    "4. For missing data \"9\", use \"N\". \n",
    "5. Don't worry about adjacent positions not in the set of SNPs. That means if you have 100 SNPs in the \".snp\" file belonging to chromosome 1, your fasta file sequence for chromosome 1 should have 100 As, Gs, Cs, Ts, and Ns.\n",
    "6. Take the time to try stubbing and adding functions to make your code more readable. Pseudocode this and figure out everything you need before you start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.6: The timing is everything! --\n",
    "In your Jupyter Notebook, try out the \"run -p\" command to check the timing of exercise 6.5. How fast is your code? What takes the longest? Can you think of any way to make your code run faster? It's okay if not, but if you want to discuss this, feel free to ask - sometimes you found the fastest way, sometimes (but not always - I'm not greatest with speed) I might have a few more ideas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.7: ANNO file\n",
    "\n",
    "In the Reich 1240K dataset, there's an ANNO file that gives more information on each individual that's been sequenced. Explore what information is found in each column. Then, write a function that returns a unique list of the 'Group IDs' available for any particular 'Publication' column. Note that tabs are used to split columns but regular spaces do not split columns. \n",
    "\n",
    "How many unique Group IDs are found for McCollScience2018?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.8: Doublecheck your data - CHALLENGE\n",
    "\n",
    "A. After Exercise 6.7, let's make sure you have a script to check amount of data available. There's two ways of doing this - do both and use the Group ID for Japan_Jomon.SG to check if they match up. \n",
    "1. In the ANNO file, you can use the SNPs hit on autosomal targets.\n",
    "2. In the GENO file, you can count the number of '9's present like before (or 0s, 1s, and 2s present). \n",
    "\n",
    "B. Note that there's only one individual with the Japan_Jomon.SG ID. But, Vietnam_BA_DongSonCulture.SG has four individuals - we might want to count these data available if even one of these individuals have data. Modify #2 so you can account for that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
